{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyP2yqEh3MCNFySqPAWsnxfB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e83c7dcf71ba4500a4aa1a1c7b4cb0ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfc736581f6a4529b20e60dcf49ece3d","IPY_MODEL_cb90a8f0d82e46eaa8630363628a02df","IPY_MODEL_0532bd78c1c94a3a93e5a0f86942ec9d"],"layout":"IPY_MODEL_4599d1e8aee949d1b9ca8e9188eeefbc"}},"cfc736581f6a4529b20e60dcf49ece3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675b7d9a6cb24c0f9b51ffe21bd7090f","placeholder":"​","style":"IPY_MODEL_bfd6da12765543a7a2675c8c84db3812","value":"tokenizer_config.json: 100%"}},"cb90a8f0d82e46eaa8630363628a02df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d215070b28b54517a4cdb7475f6ba263","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af887852010a43cd903c981074502a5a","value":49}},"0532bd78c1c94a3a93e5a0f86942ec9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77e7b54533a8441083e3750446a42b52","placeholder":"​","style":"IPY_MODEL_26b5060957f24f648c95c81919b0c76e","value":" 49.0/49.0 [00:00&lt;00:00, 3.58kB/s]"}},"4599d1e8aee949d1b9ca8e9188eeefbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"675b7d9a6cb24c0f9b51ffe21bd7090f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfd6da12765543a7a2675c8c84db3812":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d215070b28b54517a4cdb7475f6ba263":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af887852010a43cd903c981074502a5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77e7b54533a8441083e3750446a42b52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26b5060957f24f648c95c81919b0c76e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7be5679bcd44ac8a555ea43d43b55a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d66343202b646a78c602767040f1bf1","IPY_MODEL_07b3c04ef33a43138d4b1200383607c6","IPY_MODEL_328dca820f244312bd051e741e111302"],"layout":"IPY_MODEL_066241b1a94d42de849ee591880c182b"}},"0d66343202b646a78c602767040f1bf1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85f121ce18124d31af3579fb344ab355","placeholder":"​","style":"IPY_MODEL_39258a158a0b4ce1a32bd96a68f322db","value":"vocab.txt: 100%"}},"07b3c04ef33a43138d4b1200383607c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fb55538a9ec4a80b5eb3433430dbc3f","max":249928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b27d7033045b4673a73905278934a361","value":249928}},"328dca820f244312bd051e741e111302":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1694036c38fb4f39bd5d1fb6886df49e","placeholder":"​","style":"IPY_MODEL_b12e6bc2caec4442957f7087ea3e48b9","value":" 250k/250k [00:00&lt;00:00, 5.63MB/s]"}},"066241b1a94d42de849ee591880c182b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85f121ce18124d31af3579fb344ab355":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39258a158a0b4ce1a32bd96a68f322db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fb55538a9ec4a80b5eb3433430dbc3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b27d7033045b4673a73905278934a361":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1694036c38fb4f39bd5d1fb6886df49e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b12e6bc2caec4442957f7087ea3e48b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8bc839e536842a1a78bd50f2575d1cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2764f4cda5684958b80605660d6a9a42","IPY_MODEL_f60d7ad13364464b90252dace6ebeebc","IPY_MODEL_75ca18c19af94ac2bbae987486d71e6f"],"layout":"IPY_MODEL_9008324c68754f06966b77dba1026d0a"}},"2764f4cda5684958b80605660d6a9a42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2874dffaa6c84882a9b1d06374440cd5","placeholder":"​","style":"IPY_MODEL_79b41d904d9e49f3934f14350a44192b","value":"config.json: 100%"}},"f60d7ad13364464b90252dace6ebeebc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8665a93900e34f898d2161be2e0e1a8e","max":672,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce34356f920a4515860a9d27a3bb945e","value":672}},"75ca18c19af94ac2bbae987486d71e6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2e4ff20dd1446b59e2436cb82957ec7","placeholder":"​","style":"IPY_MODEL_7a0339c14df041108054fba0aac061c1","value":" 672/672 [00:00&lt;00:00, 56.4kB/s]"}},"9008324c68754f06966b77dba1026d0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2874dffaa6c84882a9b1d06374440cd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79b41d904d9e49f3934f14350a44192b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8665a93900e34f898d2161be2e0e1a8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce34356f920a4515860a9d27a3bb945e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2e4ff20dd1446b59e2436cb82957ec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a0339c14df041108054fba0aac061c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0a67cb8d2354e0c9b6b48d16e34fea4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7d6a28962f64a90806924a766226483","IPY_MODEL_4a0bbd65b8fe49fabe24598be9b27e15","IPY_MODEL_a51936b7956a4b01a5ccc7f6f6534e59"],"layout":"IPY_MODEL_83e61462a4144ffa91def1d81e061589"}},"e7d6a28962f64a90806924a766226483":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4005e6318185459f9a88f1e5b45a9897","placeholder":"​","style":"IPY_MODEL_f471fa020a3c4815bc5d63f0f34034ff","value":"model.safetensors: 100%"}},"4a0bbd65b8fe49fabe24598be9b27e15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dde009db94f4e1ca0d639b045c98838","max":1341943454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aea25173ffdb410f8efb872d133c9055","value":1341943454}},"a51936b7956a4b01a5ccc7f6f6534e59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61d0fc5acf8b4b7cbd08b0b6a76699bc","placeholder":"​","style":"IPY_MODEL_59673d9e0ae0445a8a172e0764a65f3c","value":" 1.34G/1.34G [00:05&lt;00:00, 249MB/s]"}},"83e61462a4144ffa91def1d81e061589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4005e6318185459f9a88f1e5b45a9897":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f471fa020a3c4815bc5d63f0f34034ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dde009db94f4e1ca0d639b045c98838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea25173ffdb410f8efb872d133c9055":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61d0fc5acf8b4b7cbd08b0b6a76699bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59673d9e0ae0445a8a172e0764a65f3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **KcBert-large**"],"metadata":{"id":"rskj2AeWPTI4"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ZBu9uoFqMB72","executionInfo":{"status":"ok","timestamp":1728495981518,"user_tz":-540,"elapsed":421,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yalw98yMKKN","executionInfo":{"status":"ok","timestamp":1728495999968,"user_tz":-540,"elapsed":18146,"user":{"displayName":"Rynn","userId":"12768324450751593203"}},"outputId":"f60ea18d-11d1-4144-be05-2222fc1f6968"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### 데이터 로드"],"metadata":{"id":"hvxq-2WRMdtT"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/GBT 해커톤/data/train_df_1009_v2.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/GBT 해커톤/data/test_df_1009_v2.csv')"],"metadata":{"id":"SHpz8HqCMNga","executionInfo":{"status":"ok","timestamp":1728496004474,"user_tz":-540,"elapsed":4507,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["train_df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaDTS71lYoul","executionInfo":{"status":"ok","timestamp":1728496004474,"user_tz":-540,"elapsed":5,"user":{"displayName":"Rynn","userId":"12768324450751593203"}},"outputId":"860ef35f-4fcb-460b-a2ab-7441241763ee"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 54314 entries, 0 to 54313\n","Data columns (total 4 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   ID      54314 non-null  object\n"," 1   분류      54314 non-null  object\n"," 2   제목      54314 non-null  object\n"," 3   키워드     54314 non-null  object\n","dtypes: object(4)\n","memory usage: 1.7+ MB\n"]}]},{"cell_type":"code","source":["test_df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QfhhdlQsQqap","executionInfo":{"status":"ok","timestamp":1728496004475,"user_tz":-540,"elapsed":5,"user":{"displayName":"Rynn","userId":"12768324450751593203"}},"outputId":"0c5e5f81-6fba-468d-87a8-f6b763f0abb3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 23405 entries, 0 to 23404\n","Data columns (total 3 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   ID      23405 non-null  object\n"," 1   제목      23405 non-null  object\n"," 2   키워드     23405 non-null  object\n","dtypes: object(3)\n","memory usage: 548.7+ KB\n"]}]},{"cell_type":"markdown","source":["### 모델링"],"metadata":{"id":"j5IyDg8nVrrA"}},{"cell_type":"markdown","source":["- epoch: 5\n","- learning rate: 2e-5\n","- batch size: 32\n","- max length: 256"],"metadata":{"id":"ksY6L4yZZtKT"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from tqdm import tqdm\n","import pandas as pd\n","from types import SimpleNamespace\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"oToSHITtS1n1","executionInfo":{"status":"ok","timestamp":1728496015648,"user_tz":-540,"elapsed":7036,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["TF-IDF 가중치"],"metadata":{"id":"3cxHLGC7S6Si"}},{"cell_type":"code","source":["# 카테고리별로 키워드 결합\n","category_docs = train_df.groupby('분류')['키워드'].apply(lambda x: ' '.join(x)).reset_index()\n","\n","# TF-IDF 벡터라이저 생성\n","vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(' '))\n","\n","# TF-IDF 행렬 생성\n","tfidf_matrix = vectorizer.fit_transform(category_docs['키워드'])\n","\n","# 단어와 해당 TF-IDF 점수 저장\n","feature_names = vectorizer.get_feature_names_out()\n","dense = tfidf_matrix.todense().A\n","\n","# 키워드와 가중치 저장\n","keyword_weights = {}\n","N = 300  # 상위 N개 키워드\n","for i, doc in enumerate(dense):\n","    #print(f\"분류 '{category_docs['분류'][i]}'의 상위 {N}개 키워드:\")\n","    sorted_indices = doc.argsort()[::-1][:N]\n","    for index in sorted_indices:\n","        keyword = feature_names[index]\n","        weight = doc[index]\n","        keyword_weights[keyword] = weight  # 가중치 저장\n","        #print(f\"{keyword}: {weight:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLjBtEMgS5vq","executionInfo":{"status":"ok","timestamp":1728496020892,"user_tz":-540,"elapsed":5245,"user":{"displayName":"Rynn","userId":"12768324450751593203"}},"outputId":"d3c404a3-1dea-4cc5-9434-08ece798719f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["config = {\n","    \"learning_rate\": 2e-5,\n","    \"epoch\": 5,\n","    \"batch_size\": 32\n","}\n","\n","CFG = SimpleNamespace(**config)"],"metadata":{"id":"M5W1ClAdHzbP","executionInfo":{"status":"ok","timestamp":1728496020892,"user_tz":-540,"elapsed":3,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = BertTokenizer.from_pretrained('beomi/KcBERT-large')\n","model = BertForSequenceClassification.from_pretrained('beomi/KcBERT-large', num_labels=len(train_df['분류'].unique())).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344,"referenced_widgets":["e83c7dcf71ba4500a4aa1a1c7b4cb0ea","cfc736581f6a4529b20e60dcf49ece3d","cb90a8f0d82e46eaa8630363628a02df","0532bd78c1c94a3a93e5a0f86942ec9d","4599d1e8aee949d1b9ca8e9188eeefbc","675b7d9a6cb24c0f9b51ffe21bd7090f","bfd6da12765543a7a2675c8c84db3812","d215070b28b54517a4cdb7475f6ba263","af887852010a43cd903c981074502a5a","77e7b54533a8441083e3750446a42b52","26b5060957f24f648c95c81919b0c76e","b7be5679bcd44ac8a555ea43d43b55a8","0d66343202b646a78c602767040f1bf1","07b3c04ef33a43138d4b1200383607c6","328dca820f244312bd051e741e111302","066241b1a94d42de849ee591880c182b","85f121ce18124d31af3579fb344ab355","39258a158a0b4ce1a32bd96a68f322db","6fb55538a9ec4a80b5eb3433430dbc3f","b27d7033045b4673a73905278934a361","1694036c38fb4f39bd5d1fb6886df49e","b12e6bc2caec4442957f7087ea3e48b9","d8bc839e536842a1a78bd50f2575d1cb","2764f4cda5684958b80605660d6a9a42","f60d7ad13364464b90252dace6ebeebc","75ca18c19af94ac2bbae987486d71e6f","9008324c68754f06966b77dba1026d0a","2874dffaa6c84882a9b1d06374440cd5","79b41d904d9e49f3934f14350a44192b","8665a93900e34f898d2161be2e0e1a8e","ce34356f920a4515860a9d27a3bb945e","f2e4ff20dd1446b59e2436cb82957ec7","7a0339c14df041108054fba0aac061c1","a0a67cb8d2354e0c9b6b48d16e34fea4","e7d6a28962f64a90806924a766226483","4a0bbd65b8fe49fabe24598be9b27e15","a51936b7956a4b01a5ccc7f6f6534e59","83e61462a4144ffa91def1d81e061589","4005e6318185459f9a88f1e5b45a9897","f471fa020a3c4815bc5d63f0f34034ff","1dde009db94f4e1ca0d639b045c98838","aea25173ffdb410f8efb872d133c9055","61d0fc5acf8b4b7cbd08b0b6a76699bc","59673d9e0ae0445a8a172e0764a65f3c"]},"id":"Ynvp63P0FffM","executionInfo":{"status":"ok","timestamp":1728496032829,"user_tz":-540,"elapsed":9737,"user":{"displayName":"Rynn","userId":"12768324450751593203"}},"outputId":"8ab9b5ed-1fe1-4138-9c4a-da6b6e42b8b9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e83c7dcf71ba4500a4aa1a1c7b4cb0ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7be5679bcd44ac8a555ea43d43b55a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/672 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8bc839e536842a1a78bd50f2575d1cb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0a67cb8d2354e0c9b6b48d16e34fea4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/KcBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# train 데이터셋 클래스 정의\n","class TextDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, keyword_weights, max_len=256):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.keyword_weights = keyword_weights\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        text = str(self.texts[item])\n","        label = self.labels[item] if self.labels is not None else -1\n","\n","        # BERT로 토크나이징\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        # 각 토큰에 가중치 부여\n","        input_ids = encoding['input_ids'].flatten()\n","        attention_mask = encoding['attention_mask'].flatten()\n","\n","        # 가중치 초기화\n","        weights = torch.zeros(input_ids.size(), dtype=torch.float)\n","\n","        # 토크나이즈된 단어에 대해 가중치 적용\n","        for word, weight in self.keyword_weights.items():\n","            # BERT의 토크나이저에 의해 변환된 토큰 인덱스 찾기\n","            tokens = self.tokenizer.tokenize(word)\n","            for token in tokens:\n","                token_id = self.tokenizer.convert_tokens_to_ids(token)\n","                if token_id in input_ids:\n","                    # 해당 토큰의 가중치 설정\n","                    indices = (input_ids == token_id).nonzero(as_tuple=True)[0]\n","                    weights[indices] = weight  # TF-IDF 가중치 부여\n","\n","        return {\n","            'text': text,\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': torch.tensor(label, dtype=torch.long),\n","            'weights': weights  # 가중치 추가\n","        }"],"metadata":{"id":"pttgAUj-Fikn","executionInfo":{"status":"ok","timestamp":1728496032830,"user_tz":-540,"elapsed":2,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# test 데이터셋 클래스 정의 (가중치 없음)\n","class TestDataset(Dataset):\n","    def __init__(self, texts, tokenizer, max_len=256):\n","        self.texts = texts\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        text = str(self.texts[item])\n","\n","        # BERT로 토크나이징\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        input_ids = encoding['input_ids'].flatten()\n","        attention_mask = encoding['attention_mask'].flatten()\n","\n","        return {\n","            'text': text,\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","        }"],"metadata":{"id":"0xZwWsrmPiY4","executionInfo":{"status":"ok","timestamp":1728496035664,"user_tz":-540,"elapsed":295,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 레이블 인코딩\n","label_encoder = {label: i for i, label in enumerate(train_df['분류'].unique())}\n","train_df['label'] = train_df['분류'].map(label_encoder)\n","\n","# 데이터 분할 (train -> train + validation)\n","train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['분류'], random_state=42)\n","\n","# 데이터셋 생성\n","train_dataset = TextDataset(train_df.키워드.tolist(), train_df.label.tolist(), tokenizer, keyword_weights)\n","val_dataset = TextDataset(val_df.키워드.tolist(), val_df.label.tolist(), tokenizer, keyword_weights)\n","\n","# 테스트 데이터셋 생성\n","test_dataset = TestDataset(test_df['키워드'].tolist(), tokenizer)\n","\n","# 데이터 로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)"],"metadata":{"id":"YvzoMIz_Ff4-","executionInfo":{"status":"ok","timestamp":1728496037619,"user_tz":-540,"elapsed":300,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["train_dataset[3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-C0_VSfDayq-","executionInfo":{"status":"ok","timestamp":1728496041163,"user_tz":-540,"elapsed":1088,"user":{"displayName":"Rynn","userId":"12768324450751593203"}},"outputId":"fd7b1141-d6bf-4036-baf2-70c592c061e1"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': '찐윤 수식어 이원모 산단 반도체 사활 총선 국민 용인갑 후보 이원모 대통령실 비서관 중앙 지방정부 소통 반도체 산단 적임자 경쟁국 반도체 파격투자 세액공제 대통령 반도체 산업 중요성 강조 국가산업단지 진짜 반도체 국가 산업 단지 사활 이원모 대통령실 인사 비서관 국민 후보 용인시갑 추천 전략공천 윤석열 대통령 조언 비서관 본인 강남을 공천 신청 용산 출신 인사들 양지행 비판 결정 수용 의지 공천 공관위 결정 용인갑 산업 우리나라 미래 명운 면적 차지 처인구 반도체 클러스터 국가산업단지 삼성전자 SK하이닉스 투자 이원모 대통령실 인사 비서관 처인구 선거사무소 이데일리 인터뷰 이원모 캠프 비서관 업무 연고 강조 개인 연고 대통령실 근무 정부 부처 산하 기관 대통령 인사 보좌 소통 업무 전담 산업 단지 완공 국가 현안 뒷받침 의미 공관위 결정 중간 통보 용인갑 느낌 국가산단 프로젝트 정부 지방자치단체 조율 관계자들 연락 소통 세계 반도체 산업 규모 예산 우리나라 기준 사이 산단 조성 장기 프로젝트 초기 추진력 중요 바퀴 부연 비서관 현안 해결 찐윤 핵심 윤석열계 수식어 활용 사단 검찰 재직 윤석열 막내 이명박 대통령 비자금 사건 박근혜 대통령 국정농단 대통령 국정 농단 조국 입시비리 법무 장관 자녀 입시 비리 문재인 의혹 대통령 시절 월성 원자력 발전소 경제 조작 수사 검사 사직 법률지원팀 대선 캠프 법률 대통령 복심 인사비서관 발탁 찐윤 현실 정치 고민 그간 행적 총선 출마 자연 탈원전 수사 탈원전 조국 장관 수사 적폐 낙인 원칙 원자력발전소 재정비 정권 정지 그땐 애국심 취임 윤석열 대통령 여소야대 정부 여당 입법 발목 자연 총선 도전 비서관 장관 조국혁신당 지지율 정당 지지율 지지율 비례 지지율 약진 국민들 현명 판단 비서관 국회 입성 법안 조세특례제한법 원안 반도체특별법 K칩스법 조세 특레 제한 원안 세액공제 기본 세액 공제 중견기업 대기업 중견 기업 중소기업 세액 공제 야당 반대 대기업 중견기업 중견 기업 중소기업 통과 반도체 산업 세계 전쟁 경쟁국들 파격적 투자 국가전략기술투자 세액 공제 혜택 주장 비서관 달여 기간 자세 겸손 주민들 소통 피부 민심 걱정 이젠 이야기 검사 출신 대통령실 근무 선입견 상상 이미지 아들 이야기 지역구 국민 이야기 정치인 선거 유세 이름 원모 타임 이야기 주민 숙원사업 만큼 숙원 사업 해결 다짐',\n"," 'input_ids': tensor([    2,  2829,  5107,  1931,  4117,  4071,  2451,  4165,  4137,  1789,\n","          4281, 11276,  1785,  4587,  8332,  7973, 22241,  4981, 10467,  2451,\n","          4165,  4137,  8012,  4353, 12902,  4337,  9556,  9742,  8142, 13138,\n","         11276,  1789,  4281, 22475,  4105, 10548,  4123, 11276,  3231,  4108,\n","         14103,  1862,  4787,  4239,  4231,  8012, 11276, 11240,  8539,  4093,\n","         16537,  8096, 12326, 23759,  7992, 11276,  8096, 11240, 13283,  1785,\n","          4587,  2451,  4165,  4137,  8012,  4353,  9396, 12902,  4337,  7973,\n","         10467, 22241,  4039,  4981, 11030, 11587, 29894,  8759,  8012, 24084,\n","         12902,  4337,  8487,  9134,  4027, 10643, 12572,  2355,  4457,  9471,\n","         29511,  2219,  4102,  4080,  8934,  9988, 14358, 16051, 10643, 29852,\n","          4069,  9988, 22241,  4981, 11240,  8090,  8573,  1371,  4202,  1365,\n","          4022, 12983,  2874, 20940, 11276,  3090, 21673,  4025,  8096, 12326,\n","         23759, 25169, 21572, 24249,  5623,  4103,  9486,  2451,  4165,  4137,\n","          8012,  4353,  9396, 12902,  4337,  2874, 20940,  8238, 13832,  4266,\n","          2451,  4092,  4046,  4038, 11600,  2451,  4165,  4137,  3000,  4177,\n","         12902,  4337, 11768,  2273,  4034, 16537,  8568,  2273,  4034,  8012,\n","          4353, 10876,  8028, 17892,  1789,  4159, 10961,  8012,  9396, 17188,\n","         13138, 11768,  2525,  4742, 11240, 13283,  2322,  4239,  8096,  3432,\n","          4061,   937,  4282,  4562,  9394, 29852,  4069,  9988, 12793, 27130,\n","         22241,  4981,  9892,  8096,  4457,  4281, 10419,  4818,  4104,  8028,\n","          9742, 28297,  8861,  2572,  4701, 25533,  4019, 13143, 13138,  8364,\n","         11276, 11240, 22373, 10674,  8090,  9812,  8538,  1789,  4281, 17138,\n","         10836, 10419,  4818,  4104, 12430, 12166,  4286,  8539, 12107,  1610,\n","          4132, 12902,  4337,  3432,  4061,  8594,  2829,  5107, 11628,  8759,\n","          4067,  1931,  4117,  4071, 16267, 21313,  8056,  2499,  4715,  8759,\n","          1294,  4292,  8778,  8012, 28730,     3]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'labels': tensor(43),\n"," 'weights': tensor([0.0000, 0.0000, 0.0237, 0.0291, 0.0409, 0.0189, 0.0173, 0.0414, 0.0400,\n","         0.0149, 0.0202, 0.0179, 0.0186, 0.0502, 0.0199, 0.0632, 0.0195, 0.0320,\n","         0.0248, 0.0173, 0.0414, 0.0400, 0.1615, 0.0188, 0.0188, 0.0186, 0.0247,\n","         0.0150, 0.0163, 0.0361, 0.0179, 0.0149, 0.0202, 0.0000, 0.0189, 0.0440,\n","         0.0252, 0.0179, 0.0123, 0.0228, 0.0226, 0.0127, 0.0292, 0.0274, 0.0214,\n","         0.1615, 0.0179, 0.0173, 0.0225, 0.0657, 0.0257, 0.0230, 0.0210, 0.0169,\n","         0.0000, 0.0179, 0.0230, 0.0173, 0.0326, 0.0186, 0.0502, 0.0173, 0.0414,\n","         0.0400, 0.1615, 0.0188, 0.0254, 0.0188, 0.0186, 0.0632, 0.0248, 0.0195,\n","         0.0143, 0.0320, 0.0206, 0.0173, 0.0173, 0.0161, 0.1615, 0.0000, 0.0188,\n","         0.0186, 0.0162, 0.0279, 0.1129, 0.0489, 0.0704, 0.0474, 0.0269, 0.0182,\n","         0.0000, 0.0234, 0.0222, 0.0194, 0.0166, 0.0319, 0.0387, 0.0385, 0.0489,\n","         0.0000, 0.0156, 0.0319, 0.0195, 0.0320, 0.0173, 0.0340, 0.0314, 0.0241,\n","         0.0289, 0.0474, 0.0183, 0.0338, 0.0262, 0.0198, 0.0179, 0.0139, 0.0136,\n","         0.0301, 0.0230, 0.0210, 0.0169, 0.0280, 0.0000, 0.0233, 0.0366, 0.0366,\n","         0.0326, 0.0173, 0.0414, 0.0400, 0.1615, 0.0188, 0.0254, 0.0188, 0.0186,\n","         0.0262, 0.0198, 0.0436, 0.0276, 0.0177, 0.0173, 0.0400, 0.0202, 0.0188,\n","         0.0000, 0.0173, 0.0414, 0.0400, 0.0140, 0.0272, 0.0188, 0.0186, 0.0792,\n","         0.0179, 0.0303, 0.0257, 0.0308, 0.0179, 0.0303, 0.1615, 0.0188, 0.0138,\n","         0.0264, 0.0204, 0.0149, 0.0134, 0.0534, 0.1615, 0.0254, 0.0000, 0.0361,\n","         0.0792, 0.0571, 0.0240, 0.0173, 0.0326, 0.0230, 0.0274, 0.0230, 0.0275,\n","         0.0162, 0.0217, 0.0000, 0.0168, 0.0206, 0.0000, 0.0156, 0.0319, 0.0000,\n","         0.0000, 0.0195, 0.0320, 0.0209, 0.0230, 0.0269, 0.0202, 0.0215, 0.0128,\n","         0.0289, 0.0264, 0.0150, 0.0173, 0.0242, 0.0167, 0.0711, 0.0000, 0.0257,\n","         0.0479, 0.0361, 0.0528, 0.0179, 0.0173, 0.0644, 0.0177, 0.0340, 0.0154,\n","         0.0134, 0.0149, 0.0202, 0.1781, 0.0181, 0.0215, 0.0128, 0.0289, 0.0000,\n","         0.1580, 0.0242, 0.0225, 0.0000, 0.0252, 0.0195, 0.0188, 0.0186, 0.0275,\n","         0.0162, 0.0353, 0.0000, 0.0237, 0.0160, 0.0161, 0.0083, 0.0291, 0.0409,\n","         0.0189, 0.0523, 0.0000, 0.0187, 0.0172, 0.0196, 0.0161, 0.0927, 0.0126,\n","         0.0176, 0.1615, 0.0000, 0.0000])}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# 옵티마이저 및 학습 파라미터 설정\n","optimizer = AdamW(model.parameters(), lr=CFG.learning_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anVUc_hDayoX","executionInfo":{"status":"ok","timestamp":1728496045650,"user_tz":-540,"elapsed":573,"user":{"displayName":"Rynn","userId":"12768324450751593203"}},"outputId":"fc246746-7480-4e29-8057-5cfb0a1d8b1d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# 초기화\n","patience = 2  # 개선되지 않을 경우 기다리는 에폭 수\n","best_f1 = 0.0  # 최상의 F1 스코어 초기화\n","counter = 0  # 카운터 초기화\n","\n","for epoch in range(CFG.epoch):\n","    model.train()\n","\n","    # 학습 단계\n","    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{CFG.epoch}'):\n","        optimizer.zero_grad()\n","\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Validation\n","    model.eval()\n","    val_predictions = []\n","    val_true_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc='Validating'):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            _, preds = torch.max(outputs.logits, dim=1)\n","            val_predictions.extend(preds.cpu().tolist())\n","            val_true_labels.extend(labels.cpu().tolist())\n","\n","    # F1 스코어 계산\n","    current_f1 = f1_score(val_true_labels, val_predictions, average='macro')\n","\n","    # Early stopping 체크\n","    if current_f1 > best_f1:\n","        best_f1 = current_f1  # 최상의 F1 스코어 갱신\n","        counter = 0  # 카운터 초기화\n","        torch.save(model.state_dict(), f'model_best_f1.pth')  # 모델 저장\n","        print(f\"Model saved with F1 Score: {best_f1:.4f}\")\n","    else:\n","        counter += 1  # 카운터 증가\n","\n","    print(f\"Epoch {epoch + 1}, F1 Score: {current_f1:.4f}\")\n","\n","    # Early stopping이 활성화되면 훈련 종료\n","    if counter >= patience:\n","        print(\"Early stopping triggered. Training stopped.\")\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"XSJ_SvxcPifk","outputId":"21520d35-264d-4442-9bcd-088b829ff186","executionInfo":{"status":"error","timestamp":1728496538425,"user_tz":-540,"elapsed":489895,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/5:   2%|▏         | 24/1358 [08:09<7:33:31, 20.40s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-2dcc37e97de0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 학습 단계\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Epoch {epoch + 1}/{CFG.epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-3c3745db2e74>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyword_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# BERT의 토크나이저에 의해 변환된 토큰 인덱스 찾기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mtoken_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             for token in self.basic_tokenizer.tokenize(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msplit_special_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             ):\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# words in the English Wikipedia.).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize_chinese_chars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize_chinese_chars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;31m# prevents treating the same character with different unicode codepoints as different characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0municode_normalized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NFC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize_chinese_chars\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_chinese_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_is_chinese_char\u001b[0;34m(self, cp)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0x20000\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0x2A6DF\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0x2A700\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0x2B73F\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0x2B740\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0x2B81F\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0x2B820\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0x2CEAF\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0xF900\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0xFAFF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# 테스트 세트 추론\n","model.eval()\n","test_predictions = []\n","with torch.no_grad():\n","    for batch in tqdm(test_loader, desc='Testing'):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        _, preds = torch.max(outputs.logits, dim=1)\n","        test_predictions.extend(preds.cpu().tolist())\n","\n","# 라벨 디코딩\n","label_decoder = {i: label for label, i in label_encoder.items()}\n","decoded_predictions = [label_decoder[pred] for pred in test_predictions]"],"metadata":{"id":"sjj8-9MUayjc","executionInfo":{"status":"aborted","timestamp":1728496538426,"user_tz":-540,"elapsed":5,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_submission = pd.read_csv(\"/content/drive/MyDrive/GBT 해커톤/data/sample_submission.csv\")\n","sample_submission[\"분류\"] = decoded_predictions\n","\n","sample_submission.to_csv(\"/content/drive/MyDrive/GBT 해커톤/data/submission_KcBert-large_TF-IDF_1009.csv\", encoding='UTF-8-sig', index=False)"],"metadata":{"id":"7FfwPKdwccpt","executionInfo":{"status":"aborted","timestamp":1728496538426,"user_tz":-540,"elapsed":5,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = pd.read_csv(\"/content/drive/MyDrive/GBT 해커톤/data/submission_KcBert-large_TF-IDF_1009.csv\")\n","result.head()"],"metadata":{"id":"B2RJ74l_cciL","executionInfo":{"status":"aborted","timestamp":1728496538426,"user_tz":-540,"elapsed":5,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result['분류'].value_counts()"],"metadata":{"id":"UBtEMCmNciwF","executionInfo":{"status":"aborted","timestamp":1728496538426,"user_tz":-540,"elapsed":5,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"02_7Yz45cis9","executionInfo":{"status":"aborted","timestamp":1728495476621,"user_tz":-540,"elapsed":3,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bSZsM5CxayLA","executionInfo":{"status":"aborted","timestamp":1728495476621,"user_tz":-540,"elapsed":3,"user":{"displayName":"Rynn","userId":"12768324450751593203"}}},"execution_count":null,"outputs":[]}]}