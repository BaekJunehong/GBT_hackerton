{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 지정\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../../data/test.csv\")  \n",
    "submission = pd.read_csv(\"../../data/sample_submission.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54609 entries, 0 to 54608\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      54609 non-null  object\n",
      " 1   분류      54609 non-null  object\n",
      " 2   제목      54609 non-null  object\n",
      " 3   키워드     54609 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23405 entries, 0 to 23404\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      23405 non-null  object\n",
      " 1   제목      23405 non-null  object\n",
      " 2   키워드     23405 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 548.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23405 entries, 0 to 23404\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      23405 non-null  object\n",
      " 1   분류      23405 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 365.8+ KB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['분류'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟변수 -> '분류'이고 종류 56가지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               제목  \\\n",
      "0           용인문화재단, 인문학 콘서트 ‘당신이 모르는 뮤지컬 이야기Ⅳ’ 개최   \n",
      "1                    용인 농촌테마파크, 7~8월 단체체험객 체험료 지원   \n",
      "2                 용인시, 노후주택 에너지 성능 개선 신청 18일까지 연장   \n",
      "3                 수원 용인 고양시,‘특례시’로 지정 도시경쟁력 증가 기대   \n",
      "4               용인시, 스페인 미국 국제명예자문관 위촉 대외홍보 지원 역할   \n",
      "5                      소강석 목사 \"한미 참전용사 끝까지 찾아뵐 것\"   \n",
      "6  [지방선거 D-360] 전 현직 공직출신 후보군, 행정경험 무기로 '단체장' 노린다   \n",
      "7                    용인시, '자동차세 연납제도'로 9.15% 세액공제   \n",
      "8             울진 '원자력수소 국가산단' 행정절차 '속속'...기본협약 체결   \n",
      "9                 용인시, ‘용인-화성 광역 버스정보시스템 구축사업’ 착수   \n",
      "\n",
      "                                         키워드_추출  \n",
      "0          용인, 문화재단, 인문학, 콘서트, 당신, 뮤지컬, 이야기, 개최  \n",
      "1          용인, 농촌, 테마, 파크, 단체, 체험, 객, 체험, 료, 지원  \n",
      "2              용인시, 노후, 주택, 에너지, 성능, 개선, 신청, 연장  \n",
      "3      수원, 용인, 고양시, 특례시, 로, 지정, 도시, 경쟁력, 증가, 기대  \n",
      "4  용인시, 스페인, 미국, 국제, 명예, 문관, 위촉, 대외, 홍보, 지원, 역할  \n",
      "5                       소강석, 목사, 한미, 참전용사, 끝, 것  \n",
      "6       지방선거, 전, 현직, 공직, 출신, 후보, 행정, 경험, 무기, 단체  \n",
      "7                   용인시, 자동차세, 납, 제도, 로, 세액, 공제  \n",
      "8             울진, 원자력, 수소, 국가, 행정절차, 기본, 협약, 체결  \n",
      "9      용인시, 용인, 화성, 광역, 버스, 정보, 시스템, 구축, 사업, 착수  \n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "# Okt 형태소 분석기 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# 제외할 품사 목록 정의\n",
    "'''\n",
    "Suffix: 접미사\n",
    "Determiner: 관형사\n",
    "Adverb: 부사\n",
    "Conjunction: 접속사\n",
    "Josa: 조사\n",
    "PreEomi: 선어말 어미\n",
    "Eomi: 어미\n",
    "Punctuation: 구두점\n",
    "Foreign: 외국어\n",
    "Alpha: 알파벳\n",
    "Number: 숫자\n",
    "Unknown: 알 수 없는 품사\n",
    "'''\n",
    "\n",
    "exclude_pos = ['Suffix', 'Determiner', 'Adverb', 'Conjunction', 'Josa', 'PreEomi', 'Eomi', 'Punctuation', 'Foreign', 'Alpha', 'Number', 'Unknown']\n",
    "\n",
    "# '제목' 열에서 일반명사와 고유명사만 추출하여 '키워드_추출' 열에 저장하는 함수\n",
    "def extract_nouns_and_proper_nouns_from_title(title):\n",
    "    words = okt.pos(title)\n",
    "    nouns = [word for word, pos in words if pos in ['Noun', 'ProperNoun'] and word not in exclude_pos]\n",
    "    return ', '.join(nouns)\n",
    "\n",
    "# '제목' 열에 함수 적용하여 '키워드_추출' 열 생성\n",
    "train_df['키워드_추출'] = train_df['제목'].apply(extract_nouns_and_proper_nouns_from_title)\n",
    "test_df['키워드_추출'] = test_df['제목'].apply(extract_nouns_and_proper_nouns_from_title)\n",
    "\n",
    "# 결과 출력\n",
    "print(train_df[['제목', '키워드_추출']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54609 entries, 0 to 54608\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      54609 non-null  object\n",
      " 1   분류      54609 non-null  object\n",
      " 2   제목      54609 non-null  object\n",
      " 3   키워드     54609 non-null  object\n",
      " 4   키워드_추출  54609 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54609 entries, 0 to 54608\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      54609 non-null  object\n",
      " 1   분류      54609 non-null  object\n",
      " 2   키워드_통합  54609 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# 키워드와 키워드_추출 값을 합쳐서 새로운 변수 생성\n",
    "train_df['키워드_통합'] = train_df['키워드'] + ' ' + train_df['키워드_추출']\n",
    "test_df['키워드_통합'] = test_df['키워드'] + ' ' + test_df['키워드_추출']\n",
    "\n",
    "# 변수 드랍\n",
    "train_df = train_df.drop(columns=['제목', '키워드', '키워드_추출'])\n",
    "test_df = test_df.drop(columns=['제목', '키워드', '키워드_추출'])\n",
    "\n",
    "# 결과 확인\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>분류</th>\n",
       "      <th>키워드_통합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>문화:전시_공연</td>\n",
       "      <td>용인문화재단,인문학,콘서트,뮤지컬,이야기,개최,인문학,콘서트,뮤지컬,이야기,용인문화...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>지역</td>\n",
       "      <td>용인,농촌,테마파크,단체,체험객,체험료,지원,15일,체험일,기준,용인시통합예약사이트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>지역</td>\n",
       "      <td>용인시,노후,주택,에너지,성능,개선,신청,연장,용인시청,용인시,노후,건축물,환경친화...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>지역</td>\n",
       "      <td>수원,용인,고양시,특례시,지정,도시경쟁력,증가,경기,도내,인구,수원,고양,용인시,특...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>국제</td>\n",
       "      <td>용인시,스페인,미국,국제,명예,자문관,위촉,역할,대외,홍보,지원,용인시,권태면,주코...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID        분류                                             키워드_통합\n",
       "0  TRAIN_00000  문화:전시_공연  용인문화재단,인문학,콘서트,뮤지컬,이야기,개최,인문학,콘서트,뮤지컬,이야기,용인문화...\n",
       "1  TRAIN_00001        지역  용인,농촌,테마파크,단체,체험객,체험료,지원,15일,체험일,기준,용인시통합예약사이트...\n",
       "2  TRAIN_00002        지역  용인시,노후,주택,에너지,성능,개선,신청,연장,용인시청,용인시,노후,건축물,환경친화...\n",
       "3  TRAIN_00003        지역  수원,용인,고양시,특례시,지정,도시경쟁력,증가,경기,도내,인구,수원,고양,용인시,특...\n",
       "4  TRAIN_00004        국제  용인시,스페인,미국,국제,명예,자문관,위촉,역할,대외,홍보,지원,용인시,권태면,주코..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23405 entries, 0 to 23404\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      23405 non-null  object\n",
      " 1   키워드_통합  23405 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 365.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>키워드_통합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>김태수,별세,김태수씨,서울,광남초등학,교장,별세,김윤정,이노코리아,대표,희정,한성대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>신규,확진,나흘,세자릿수,방역당국,핼러윈,풍선,효과,차단,총력,감염증,신종,코로나바...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>전해철,장관,재정,분권,강화,지방자치,2.0,시대,마중물,마련,장관,전해철,행정안전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>용인시,구인,장애인,구직,만남,채용,행사,노호근,용인특례시,장애인,취업,지원,대회의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>지자체,경기,북동부,지역,산업단지,혁신단위,설정,전략,지역,연계,특성,제시,경기도경...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                             키워드_통합\n",
       "0  TEST_00000  김태수,별세,김태수씨,서울,광남초등학,교장,별세,김윤정,이노코리아,대표,희정,한성대...\n",
       "1  TEST_00001  신규,확진,나흘,세자릿수,방역당국,핼러윈,풍선,효과,차단,총력,감염증,신종,코로나바...\n",
       "2  TEST_00002  전해철,장관,재정,분권,강화,지방자치,2.0,시대,마중물,마련,장관,전해철,행정안전...\n",
       "3  TEST_00003  용인시,구인,장애인,구직,만남,채용,행사,노호근,용인특례시,장애인,취업,지원,대회의...\n",
       "4  TEST_00004  지자체,경기,북동부,지역,산업단지,혁신단위,설정,전략,지역,연계,특성,제시,경기도경..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "수정된 데이터프레임:\n",
      "                ID        분류  \\\n",
      "0      TRAIN_00000  문화:전시_공연   \n",
      "1      TRAIN_00001        지역   \n",
      "2      TRAIN_00002        지역   \n",
      "3      TRAIN_00003        지역   \n",
      "4      TRAIN_00004        국제   \n",
      "...            ...       ...   \n",
      "54604  TRAIN_54604        국제   \n",
      "54605  TRAIN_54605  사회:교육_시험   \n",
      "54606  TRAIN_54606        지역   \n",
      "54607  TRAIN_54607        지역   \n",
      "54608  TRAIN_54608        지역   \n",
      "\n",
      "                                                  키워드_통합  \n",
      "0      용인문화재단, 인문학, 콘서트, 뮤지컬, 이야기, 개최, 인문학, 콘서트, 뮤지컬,...  \n",
      "1      용인, 농촌, 테마파크, 단체, 체험객, 체험료, 지원, 체험일, 기준, 용인시통합...  \n",
      "2      용인시, 노후, 주택, 에너지, 성능, 개선, 신청, 연장, 용인시청, 용인시, 노...  \n",
      "3      수원, 용인, 고양시, 특례시, 지정, 도시경쟁력, 증가, 경기, 도내, 인구, 수...  \n",
      "4      용인시, 스페인, 미국, 국제, 명예, 자문관, 위촉, 역할, 대외, 홍보, 지원,...  \n",
      "...                                                  ...  \n",
      "54604  용인, 아파트, 여성, 아들, 추락, 극단, 선택, 추정, 경찰, 현장, 유서, 경...  \n",
      "54605  용인시, 위탁, 부모, 보수, 교육, 용인시, 경기, 남부, 가정, 위탁, 지원, ...  \n",
      "54606  용인시, 플랫폼, 시티, 국토부, 신청, 사업, 인정, 협의, 경기, 용인시, 중앙...  \n",
      "54607  주민자치위원회, 용인시, 이동읍, 주민, 자치, 위원회, 가구, 밑반찬, 지원, 용...  \n",
      "54608  용인시, 용인시공무원노조, 국무총리, 수상, 용인, 홍화표, 경기, 용인시, 용인시...  \n",
      "\n",
      "[54609 rows x 3 columns]\n",
      "\n",
      "제거된 단어들:\n",
      "['18일', '15일', '7월', '8월', '50%', '22일', '20명', '10명', '70명', '36종류']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# 불용어 제거\n",
    "removed_keywords = []\n",
    "\n",
    "def remove_invalid_keywords(keywords):\n",
    "    pattern = re.compile(\n",
    "        r'[A-Za-z]+[가-힣\\u4E00-\\u9FFF]+|'  # 영어+한글\n",
    "        r'[0-9]+[가-힣\\u4E00-\\u9FFF]+|'     # 숫자+한글\n",
    "        r'[0-9]+[A-Za-z]+|'                 # 숫자+영어\n",
    "        r'[가-힣]+[A-Za-z\\u4E00-\\u9FFF]+|'  # 한글+영어\n",
    "        r'[가-힣]+[0-9]+|'                  # 한글+숫자\n",
    "        r'[A-Za-z]+[0-9]+|'                 # 영어+숫자\n",
    "        r'[\\u4E00-\\u9FFF]+|'                # 한자\n",
    "        r'[0-9]+(\\.[0-9]+)?%|'              # 숫자+퍼센트\n",
    "        r'[0-9]+|'                          # 숫자\n",
    "        r'[A-Za-z]+'                        # 영어\n",
    "    )\n",
    "    valid_keywords = []\n",
    "    for word in keywords.split(','):\n",
    "        word = word.strip()\n",
    "        if not word or pattern.match(word):  # 공백이거나 패턴에 맞는 단어 제거\n",
    "            removed_keywords.append(word)\n",
    "        else:\n",
    "            valid_keywords.append(word)\n",
    "    return ', '.join(valid_keywords)\n",
    "\n",
    "# 원본 데이터에서 해당 키워드들을 제거\n",
    "train_df['키워드_통합'] = train_df['키워드_통합'].apply(remove_invalid_keywords)\n",
    "test_df['키워드_통합'] = test_df['키워드_통합'].apply(remove_invalid_keywords)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n수정된 데이터프레임:\")\n",
    "print(train_df)\n",
    "\n",
    "# 제거된 단어들 출력\n",
    "print(\"\\n제거된 단어들:\")\n",
    "print(removed_keywords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "제거된 단어들 상위 20개:\n",
      "코로나19: 20593\n",
      "A씨: 13183\n",
      "Yongin: 11405\n",
      "City: 7544\n",
      "1만: 6429\n",
      "city: 5846\n",
      ": 5726\n",
      "SK하이닉스: 5603\n",
      "AI: 5271\n",
      "Google: 5108\n",
      "SK: 4812\n",
      "1년: 4811\n",
      "GTX: 4286\n",
      "LH: 4246\n",
      "Translate: 4229\n",
      "Lee: 4051\n",
      "3년: 4024\n",
      "2년: 3938\n",
      "Gyeonggi: 3858\n",
      "B씨: 3769\n"
     ]
    }
   ],
   "source": [
    "# 제거된 단어들의 빈도 계산 및 상위 20개 출력\n",
    "keyword_counter = Counter(removed_keywords)\n",
    "top_10_keywords = keyword_counter.most_common(20)\n",
    "\n",
    "print(\"\\n제거된 단어들 상위 20개:\")\n",
    "for keyword, count in top_10_keywords:\n",
    "    print(f\"{keyword}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대분류 기준으로 공통단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "지역       26950\n",
       "경제       10534\n",
       "사회        8245\n",
       "정치        2521\n",
       "문화        2500\n",
       "스포츠       2035\n",
       "IT_과학     1487\n",
       "국제         337\n",
       "Name: 분류_대분류, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '분류' 열에서 앞부분만 추출하여 '분류_대분류'라는 새로운 열에 저장\n",
    "train_df['분류_대분류'] = train_df['분류'].apply(lambda x: x.split(':')[0])\n",
    "\n",
    "# 결과 확인\n",
    "train_df['분류_대분류'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54609"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_common_words_and_remove(num_categories=8, top_n=100, com_counts=10, train_df=train_df, test_df=test_df):\n",
    "    # '분류_대분류'의 각 범주에 속하는 단어들을 추출\n",
    "    category_words = {category: [] for category in train_df[\"분류_대분류\"].unique()}\n",
    "\n",
    "    for category in category_words.keys():\n",
    "        words = train_df.loc[train_df[\"분류_대분류\"] == category, \"키워드_통합\"].apply(lambda x: x.split(',')).tolist()\n",
    "        category_words[category] = [word for sublist in words for word in sublist]\n",
    "\n",
    "    # 각 범주에 속하는 단어들을 카운팅\n",
    "    word_counts = {category: Counter(words) for category, words in category_words.items()}\n",
    "\n",
    "    # 지정된 범주 갯수에 속하는 단어들을 찾기\n",
    "    common_words = set()\n",
    "    for word in word_counts[list(word_counts.keys())[0]].keys():\n",
    "        count = sum(1 for category in word_counts.keys() if word in word_counts[category] and word_counts[category][word] >= com_counts)\n",
    "        if count == num_categories:\n",
    "            common_words.add(word)\n",
    "\n",
    "    # 지정된 범주 갯수에 속하는 단어와 그 갯수를 계산\n",
    "    common_word_counts = {word: sum(word_counts[category][word] for category in word_counts.keys()) for word in common_words}\n",
    "\n",
    "    # 단어들을 갯수 기준으로 정렬하고 상위 N개를 선택\n",
    "    top_common_words = sorted(common_word_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    print(f\"상위 {top_n}개의 단어 확인\")\n",
    "\n",
    "    # 상위 N개의 단어와 그 갯수, 그리고 각 범주에서의 갯수를 출력\n",
    "    for word, total_count in top_common_words:\n",
    "        category_counts = {category: word_counts[category][word] for category in word_counts.keys()}\n",
    "        print(f\"단어: {word}, 총 갯수: {total_count}, 각 범주에서의 갯수: {category_counts}\")\n",
    "        \n",
    "    # 총 몇 개의 단어가 겹치는지 출력\n",
    "    print(f\"총 {len(common_words)}개의 단어가 겹칩니다.\")\n",
    "\n",
    "    # top_n 기준으로 겹치는 단어들을 '키워드' 열에서 제거하고 새로운 열에 저장\n",
    "    top_common_words_set = set(word for word, _ in top_common_words)\n",
    "    \n",
    "    def remove_top_common_words(keywords):\n",
    "        return ', '.join([word for word in keywords.split(',') if word not in top_common_words_set])\n",
    "\n",
    "    train_df['키워드_통합'] = train_df['키워드_통합'].apply(remove_top_common_words)\n",
    "    test_df['키워드_통합'] = test_df['키워드_통합'].apply(remove_top_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_categories : 공통단어로 간주할 범주의 수  \n",
    "top_n : 상위 N개의 공통 단어를 선택  \n",
    "com_counts : 범주에서 단어가 공통 단어로 간주되기 위해 나타나야 하는 최소 횟수를 지정  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상위 100개의 단어 확인\n",
      "단어:  용인시, 총 갯수: 94682, 각 범주에서의 갯수: {'문화': 3729, '지역': 51521, '국제': 471, '정치': 4083, '경제': 17801, '사회': 11619, '스포츠': 2661, 'IT_과학': 2797}\n",
      "단어:  용인, 총 갯수: 70878, 각 범주에서의 갯수: {'문화': 3573, '지역': 36190, '국제': 266, '정치': 3974, '경제': 20278, '사회': 4149, '스포츠': 1250, 'IT_과학': 1198}\n",
      "단어:  지역, 총 갯수: 53726, 각 범주에서의 갯수: {'문화': 1400, '지역': 29437, '국제': 131, '정치': 3238, '경제': 13148, '사회': 5264, '스포츠': 183, 'IT_과학': 925}\n",
      "단어:  지원, 총 갯수: 53337, 각 범주에서의 갯수: {'문화': 533, '지역': 32280, '국제': 105, '정치': 1795, '경제': 13172, '사회': 4118, '스포츠': 252, 'IT_과학': 1082}\n",
      "단어:  시장, 총 갯수: 49593, 각 범주에서의 갯수: {'문화': 1643, '지역': 25853, '국제': 327, '정치': 4068, '경제': 13638, '사회': 2286, '스포츠': 811, 'IT_과학': 967}\n",
      "단어:  경기도, 총 갯수: 45053, 각 범주에서의 갯수: {'문화': 1278, '지역': 25564, '국제': 126, '정치': 2357, '경제': 9318, '사회': 3970, '스포츠': 1867, 'IT_과학': 573}\n",
      "단어:  경기, 총 갯수: 39547, 각 범주에서의 갯수: {'문화': 1065, '지역': 15380, '국제': 226, '정치': 2320, '경제': 9460, '사회': 7247, '스포츠': 3245, 'IT_과학': 604}\n",
      "단어:  이날, 총 갯수: 17318, 각 범주에서의 갯수: {'문화': 743, '지역': 7710, '국제': 128, '정치': 1891, '경제': 2319, '사회': 3816, '스포츠': 506, 'IT_과학': 205}\n",
      "단어:  상황, 총 갯수: 12470, 각 범주에서의 갯수: {'문화': 382, '지역': 4980, '국제': 110, '정치': 795, '경제': 2835, '사회': 2928, '스포츠': 215, 'IT_과학': 225}\n",
      "단어:  사진, 총 갯수: 8553, 각 범주에서의 갯수: {'문화': 943, '지역': 3704, '국제': 100, '정치': 476, '경제': 1483, '사회': 1213, '스포츠': 303, 'IT_과학': 331}\n",
      "단어:  세계, 총 갯수: 7639, 각 범주에서의 갯수: {'문화': 808, '지역': 1462, '국제': 114, '정치': 273, '경제': 3950, '사회': 278, '스포츠': 384, 'IT_과학': 370}\n",
      "단어:  한국, 총 갯수: 5962, 각 범주에서의 갯수: {'문화': 1044, '지역': 1038, '국제': 348, '정치': 297, '경제': 1781, '사회': 547, '스포츠': 674, 'IT_과학': 233}\n",
      "총 12개의 단어가 겹칩니다.\n"
     ]
    }
   ],
   "source": [
    "find_common_words_and_remove(num_categories=8, com_counts=100) # top_n은 default인 100 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상위 100개의 단어 확인\n",
      "단어:   진행, 총 갯수: 31208, 각 범주에서의 갯수: {'문화': 2185, '지역': 15842, '국제': 82, '정치': 929, '경제': 6248, '사회': 4316, '스포츠': 549, 'IT_과학': 1057}\n",
      "단어:   관계자, 총 갯수: 22464, 각 범주에서의 갯수: {'문화': 705, '지역': 11946, '국제': 98, '정치': 591, '경제': 4994, '사회': 3056, '스포츠': 303, 'IT_과학': 771}\n",
      "단어:   대표, 총 갯수: 14928, 각 범주에서의 갯수: {'문화': 1040, '지역': 4527, '국제': 42, '정치': 3295, '경제': 3146, '사회': 1400, '스포츠': 929, 'IT_과학': 549}\n",
      "단어:   시작, 총 갯수: 13749, 각 범주에서의 갯수: {'문화': 1225, '지역': 5546, '국제': 75, '정치': 714, '경제': 3275, '사회': 1933, '스포츠': 381, 'IT_과학': 600}\n",
      "총 4개의 단어가 겹칩니다.\n"
     ]
    }
   ],
   "source": [
    "find_common_words_and_remove(num_categories=7, com_counts=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_and_remove_low_occurrence_keywords(train_df, test_df, threshold=3):\n",
    "    # '키워드' 열의 각 값을 쉼표로 분리하여 리스트로 변환\n",
    "    train_df['키워드_리스트'] = train_df['키워드_통합'].apply(lambda x: x.split(','))\n",
    "    test_df['키워드_리스트'] = test_df['키워드_통합'].apply(lambda x: x.split(','))\n",
    "\n",
    "    # '분류_대분류' 별로 단어들을 추출하고 카운팅\n",
    "    category_keywords = {category: [] for category in train_df[\"분류_대분류\"].unique()}\n",
    "\n",
    "    for category in category_keywords.keys():\n",
    "        words = train_df.loc[train_df[\"분류_대분류\"] == category, \"키워드_리스트\"].tolist()\n",
    "        category_keywords[category] = [word.strip() for sublist in words for word in sublist if word.strip()]\n",
    "\n",
    "    # 각 '분류_대분류' 별로 단어들을 카운팅하고 단어가 threshold 이하로 존재하는 경우를 찾기\n",
    "    low_occurrence_words = set()\n",
    "    for category, words in category_keywords.items():\n",
    "        word_counts = Counter(words)\n",
    "        low_occurrence_words.update({word for word, count in word_counts.items() if count <= threshold})\n",
    "\n",
    "    # 단어가 threshold 이하로 존재하는 경우를 '키워드' 열에서 제거\n",
    "    def remove_low_occurrence_words(keywords):\n",
    "        return ', '.join([word.strip() for word in keywords.split(',') if word.strip() and word.strip() not in low_occurrence_words])\n",
    "\n",
    "    train_df['키워드_통합'] = train_df['키워드_통합'].apply(remove_low_occurrence_words)\n",
    "\n",
    "    # test_df에서도 동일한 단어를 제거\n",
    "    def remove_low_occurrence_words_from_test(keywords):\n",
    "        return ', '.join([word.strip() for word in keywords.split(',') if word.strip() and word.strip() not in low_occurrence_words])\n",
    "\n",
    "    test_df['키워드_통합'] = test_df['키워드_통합'].apply(remove_low_occurrence_words_from_test)\n",
    "\n",
    "    # 제거 후 각 '분류_대분류' 별로 하위 10개의 단어와 그 갯수를 출력\n",
    "    for category in category_keywords.keys():\n",
    "        words = train_df.loc[train_df[\"분류_대분류\"] == category, \"키워드_통합\"].apply(lambda x: x.split(',')).tolist()\n",
    "        words = [word.strip() for sublist in words for word in sublist if word.strip()]\n",
    "        word_counts = Counter(words)\n",
    "        bottom_keywords = word_counts.most_common()[:-11:-1]\n",
    "        print(f\"분류_대분류: {category}\")\n",
    "        for word, count in bottom_keywords:\n",
    "            print(f\"  단어: {word}, 갯수: {count}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 실행\n",
    "count_and_remove_low_occurrence_keywords(train_df, test_df, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # '키워드' 열의 모든 단어들을 리스트로 모으기\n",
    "# all_keywords = []\n",
    "# train_df['키워드'].apply(lambda x: all_keywords.extend(x.split(',')))\n",
    "\n",
    "# # 모든 단어들의 빈도 계산\n",
    "# keyword_counts = pd.Series(all_keywords).value_counts()\n",
    "\n",
    "# # 갯수가 1개 이하인 키워드들 필터링\n",
    "# low_frequency_keywords = keyword_counts[keyword_counts <= 1].index.tolist()\n",
    "# print(\"\\n갯수가 1개 이하인 키워드들:\")\n",
    "# low_frequency_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이재명, 큰절, 눈물, 상처, 이재명, 더불어민주당, 대선, 후보, 연일, 반성, 사죄, 자신, 약점, 도덕성, 민주당, 사과, 중도층, 지지, 대선, 최대, 분기점, 연휴, 후보, 상태, 지지율, 정체, 타개, 위기감, 작용, 후보, 경기, 성남, 상대원, 시장, 자신, 유년기, 시절, 언급, 눈물, 자리, 이낙연, 민주당, 대표, 동행, 후보, 초등학교, 산꼭대기, 어머니, 화장실, 출근, 공장, 행복, 눈시울, 후보, 아버지, 시장, 청소, 노동자, 어머니, 시장, 공중, 화장실, 이용자, 소변, 대변, 설명, 화장실, 아들, 어머니, 거짓말, 판검사, 실력, 변호사, 노력, 자리, 상처, 토로, 후보, 형수, 욕설, 가족, 논란, 고개, 민주당, 반성, 강조, 후보, 경기, 용인시, 경기도, 공약, 윤호중, 원내, 대표, 민주당, 의원, 예정, 큰절, 후보, 사죄, 큰절, 후보, 민주당, 개혁, 진보, 세력, 핵심, 가치, 공정, 측면, 부족, 국민들, 남불, 질책, 생각, 관계자, 민주당, 선대위, 선대위, 현상, 지지율, 정체, 위기의식, 후보, 차원, 설명, 후보, 국민, 주장, 세대포위론, 적극, 반박, 세대포용, 세대포위론, 전폭적, 지지, 부모, 세대, 지지, 전략, 후보, 경기, 유세, 국민, 겨냥, 염장, 이익, 타인, 고통, 강요, 분열, 증오, 이용, 포위, 세대포위론, 비판, 박재현'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # '증오'가 정확히 일치하는 행 필터링\n",
    "# filtered_df = train_df[train_df['키워드'].str.contains(r'\\b증오\\b', na=False)]\n",
    "\n",
    "# # 결과 출력\n",
    "# filtered_df.iloc[3]['키워드']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # '키워드' 열의 모든 단어들을 리스트로 모으기\n",
    "# all_keywords = []\n",
    "# train_df['키워드'].apply(lambda x: all_keywords.extend(x.split(',')))\n",
    "\n",
    "# # 모든 단어들의 빈도 계산\n",
    "# keyword_counts = pd.Series(all_keywords).value_counts()\n",
    "\n",
    "# # 갯수가 2개 이하인 키워드들 필터링\n",
    "# low_frequency_keywords = keyword_counts[keyword_counts == 2].index.tolist()\n",
    "# print(\"\\n갯수가 2개인 키워드들:\")\n",
    "# low_frequency_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # '키워드' 열의 모든 단어들을 리스트로 모으기\n",
    "# all_keywords = []\n",
    "# train_df['키워드'].apply(lambda x: all_keywords.extend(x.split(',')))\n",
    "\n",
    "# # 모든 단어들의 빈도 계산\n",
    "# keyword_counts = pd.Series(all_keywords).value_counts()\n",
    "\n",
    "# # 갯수가 1개 이하인 키워드들 필터링\n",
    "# low_frequency_keywords = keyword_counts[keyword_counts <= 1].index.tolist()\n",
    "# print(\"\\n갯수가 1개 이하인 키워드들:\")\n",
    "# print(low_frequency_keywords)\n",
    "\n",
    "# # 갯수가 1개 이하인 키워드들을 제거하는 함수\n",
    "# def remove_low_frequency_keywords(keywords):\n",
    "#     valid_keywords = [word.strip() for word in keywords.split(',') if word.strip() not in low_frequency_keywords]\n",
    "#     return ', '.join(valid_keywords)\n",
    "\n",
    "# # 원본 데이터에서 해당 키워드들을 제거\n",
    "# train_df['키워드'] = train_df['키워드'].apply(remove_low_frequency_keywords)\n",
    "# test_df['키워드'] = test_df['키워드'].apply(remove_low_frequency_keywords)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(\"\\n수정된 데이터프레임:\")\n",
    "# print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # '키워드' 열의 모든 단어들을 리스트로 모으기\n",
    "# all_keywords = []\n",
    "# train_df['키워드'].apply(lambda x: all_keywords.extend(x.split(',')))\n",
    "\n",
    "# # 모든 단어들의 빈도 계산\n",
    "# keyword_counts = pd.Series(all_keywords).value_counts()\n",
    "\n",
    "# # 갯수가 2개인 키워드들 필터링\n",
    "# low_frequency_keywords = keyword_counts[keyword_counts == 2].index.tolist()\n",
    "# print(\"\\n갯수가 2개인 키워드들:\")\n",
    "# print(low_frequency_keywords)\n",
    "\n",
    "# # 갯수가 2개인 키워드들을 제거하는 함수\n",
    "# def remove_low_frequency_keywords(keywords):\n",
    "#     valid_keywords = [word.strip() for word in keywords.split(',') if word.strip() not in low_frequency_keywords]\n",
    "#     return ', '.join(valid_keywords)\n",
    "\n",
    "# # 원본 데이터에서 해당 키워드들을 제거\n",
    "# train_df['키워드'] = train_df['키워드'].apply(remove_low_frequency_keywords)\n",
    "# test_df['키워드'] = test_df['키워드'].apply(remove_low_frequency_keywords)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(\"\\n수정된 데이터프레임:\")\n",
    "# print(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
