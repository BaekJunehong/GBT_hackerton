{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 모델 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "# 경고 메시지 억제\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 불러오기 : 영문기사 제거(+html 제거) 데이터셋 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/train_df_translate_del.csv\")\n",
    "df_test = pd.read_csv(\"../../data/test_df_translate_del.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처러 1. 중복 행 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(subset=['제목', '키워드'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처러 2. url 주소 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 제거할 단어 리스트\n",
    "remove_words = ['http', 'www.', '.kr', '.net', '.com']\n",
    "\n",
    "def remove_specific_words(text):\n",
    "    words = text.split(',')\n",
    "    filtered_words = [word for word in words if not any(remove_word in word for remove_word in remove_words)]\n",
    "    return ','.join(filtered_words)\n",
    "\n",
    "# '키워드' 열에 함수 적용\n",
    "df_train['키워드'] = df_train['키워드'].apply(remove_specific_words)\n",
    "df_test['키워드'] = df_test['키워드'].apply(remove_specific_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54315, 4), (23405, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorization + Logistic Regression (max_iter=50, C=0.01) - Accuracy: 0.8196630764982049, Macro F1-score: 0.6191453439964156\n",
      "Count Vectorization + Logistic Regression (max_iter=50, C=0.1) - Accuracy: 0.8390868084322931, Macro F1-score: 0.6733327968773705\n",
      "Count Vectorization + Logistic Regression (max_iter=50, C=1) - Accuracy: 0.8389026972291264, Macro F1-score: 0.6739632528416808\n",
      "Count Vectorization + Logistic Regression (max_iter=50, C=10) - Accuracy: 0.8373377520022093, Macro F1-score: 0.6735982794742669\n",
      "Count Vectorization + Logistic Regression (max_iter=50, C=100) - Accuracy: 0.8344840283531253, Macro F1-score: 0.6709326306291497\n",
      "Count Vectorization + Logistic Regression (max_iter=100, C=0.01) - Accuracy: 0.8190186872871215, Macro F1-score: 0.6134241321173789\n",
      "Count Vectorization + Logistic Regression (max_iter=100, C=0.1) - Accuracy: 0.84009942004971, Macro F1-score: 0.6737647361372543\n",
      "Count Vectorization + Logistic Regression (max_iter=100, C=1) - Accuracy: 0.8407438092607935, Macro F1-score: 0.6811214132075255\n",
      "Count Vectorization + Logistic Regression (max_iter=100, C=10) - Accuracy: 0.8382583080180429, Macro F1-score: 0.6803298285294064\n",
      "Count Vectorization + Logistic Regression (max_iter=100, C=100) - Accuracy: 0.835956917978459, Macro F1-score: 0.669774200778453\n",
      "Count Vectorization + Logistic Regression (max_iter=150, C=0.01) - Accuracy: 0.8194789652950382, Macro F1-score: 0.6141364271900837\n",
      "Count Vectorization + Logistic Regression (max_iter=150, C=0.1) - Accuracy: 0.8397311976433766, Macro F1-score: 0.6732381327518752\n",
      "Count Vectorization + Logistic Regression (max_iter=150, C=1) - Accuracy: 0.8407438092607935, Macro F1-score: 0.6762218286986579\n",
      "Count Vectorization + Logistic Regression (max_iter=150, C=10) - Accuracy: 0.8378900856117095, Macro F1-score: 0.6760513878787006\n",
      "Count Vectorization + Logistic Regression (max_iter=150, C=100) - Accuracy: 0.837245696400626, Macro F1-score: 0.6782692358086378\n",
      "Count Vectorization + Logistic Regression (max_iter=200, C=0.01) - Accuracy: 0.8195710208966216, Macro F1-score: 0.613935816563724\n",
      "Count Vectorization + Logistic Regression (max_iter=200, C=0.1) - Accuracy: 0.8395470864402099, Macro F1-score: 0.6730576127876685\n",
      "Count Vectorization + Logistic Regression (max_iter=200, C=1) - Accuracy: 0.8404676424560434, Macro F1-score: 0.6797353884703983\n",
      "Count Vectorization + Logistic Regression (max_iter=200, C=10) - Accuracy: 0.8365092515879591, Macro F1-score: 0.6709605873015378\n",
      "Count Vectorization + Logistic Regression (max_iter=200, C=100) - Accuracy: 0.8347601951578754, Macro F1-score: 0.6681623896280084\n",
      "Count Vectorization + Logistic Regression (max_iter=250, C=0.01) - Accuracy: 0.8194789652950382, Macro F1-score: 0.6139149589115606\n",
      "Count Vectorization + Logistic Regression (max_iter=250, C=0.1) - Accuracy: 0.8391788640338764, Macro F1-score: 0.6727434404813438\n",
      "Count Vectorization + Logistic Regression (max_iter=250, C=1) - Accuracy: 0.8397311976433766, Macro F1-score: 0.6743543032585446\n",
      "Count Vectorization + Logistic Regression (max_iter=250, C=10) - Accuracy: 0.8370615851974592, Macro F1-score: 0.6705703208082185\n"
     ]
    }
   ],
   "source": [
    "# 텍스트와 레이블 분리\n",
    "X = df_train['키워드']  # 키워드 컬럼\n",
    "y = df_train['분류']  # 카테고리 컬럼\n",
    "\n",
    "# 데이터 분할 (클래스 비율 동일하게 유지)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_valid_encoded = label_encoder.transform(y_valid)\n",
    "\n",
    "# Count Vectorization\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_valid_count = count_vectorizer.transform(X_valid)\n",
    "\n",
    "# 반복 횟수 및 규제 강도 설정\n",
    "max_iters = [50, 100, 150, 200, 250, 300]\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for max_iter in max_iters:\n",
    "    for C in Cs:\n",
    "        # 로지스틱 회귀 모델 정의\n",
    "        model_count = LogisticRegression(random_state=RANDOM_STATE, max_iter=max_iter, C=C)\n",
    "\n",
    "        # 모델 학습\n",
    "        model_count.fit(X_train_count, y_train_encoded)\n",
    "\n",
    "        # 예측\n",
    "        y_valid_pred = model_count.predict(X_valid_count)\n",
    "\n",
    "        # 성능 평가\n",
    "        accuracy = accuracy_score(y_valid_encoded, y_valid_pred)\n",
    "        macro_f1 = f1_score(y_valid_encoded, y_valid_pred, average='macro')\n",
    "        print(f\"Count Vectorization + Logistic Regression (max_iter={max_iter}, C={C}) - Accuracy: {accuracy}, Macro F1-score: {macro_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorization + Logistic Regression (max_iter=100, C=1)     \n",
    "- Accuracy: 0.8407438092607935, Macro F1-score: 0.6811214132075255    \n",
    "- max_iter : (default) 100   \n",
    "- C : (default) 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 데이터로 학습하여 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드만 total 코드에 실행시키면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일로 저장된 결과:\n",
      "           ID        분류\n",
      "0  TEST_00000        지역\n",
      "1  TEST_00001   사회:사회일반\n",
      "2  TEST_00002  정치:행정_자치\n",
      "3  TEST_00003  경제:취업_창업\n",
      "4  TEST_00004        지역\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ----- 1. 데이터 불러오기 ----- #\n",
    "\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "# 경고 메시지 억제\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 영문기사 및 html 문 제거한 데이터 사용\n",
    "df_train = pd.read_csv(\"../../data/train_df_translate_del.csv\")\n",
    "df_test = pd.read_csv(\"../../data/test_df_translate_del.csv\")\n",
    "\n",
    "\n",
    "# ----- 2. 전처리 ----- #\n",
    "\n",
    "## 전처리 1. 중복 제거\n",
    "df_train.drop_duplicates(subset=['제목', '키워드'], keep='first', inplace=True)\n",
    "\n",
    "## 전처리 2. url 제거\n",
    "remove_words = ['http', 'www.', '.kr', '.net', '.com'] # 제거할 단어 리스트\n",
    "\n",
    "def remove_specific_words(text):\n",
    "    words = text.split(',')\n",
    "    filtered_words = [word for word in words if not any(remove_word in word for remove_word in remove_words)]\n",
    "    return ','.join(filtered_words)\n",
    "\n",
    "# ----- 3. 모델링(학습) ----- #\n",
    "\n",
    "# '키워드' 열에 함수 적용\n",
    "df_train['키워드'] = df_train['키워드'].apply(remove_specific_words)\n",
    "df_test['키워드'] = df_test['키워드'].apply(remove_specific_words)\n",
    "\n",
    "# 텍스트와 레이블 분리\n",
    "X_train = df_train['키워드']  # 키워드 컬럼\n",
    "y_train = df_train['분류']  # 카테고리 컬럼\n",
    "X_test = df_test['키워드']\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Count Vectorization\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# 로지스틱 회귀 모델 정의\n",
    "model_count = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "# 모델 학습\n",
    "model_count.fit(X_train_count, y_train_encoded)\n",
    "\n",
    "# ----- 4. 모델링(예측) ----- #\n",
    "# 예측\n",
    "count_predictions = model_count.predict(X_test_count)   \n",
    "\n",
    "# 예측 결과를 데이터프레임으로 변환\n",
    "count_results = pd.DataFrame({'ID': df_test['ID'], '분류': label_encoder.inverse_transform(count_predictions)})\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "count_results.to_csv(\"1016_count_vectorization_lr_predictions.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 저장된 결과 확인\n",
    "print(\"CSV 파일로 저장된 결과:\")\n",
    "print(count_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
