{"cells":[{"cell_type":"markdown","metadata":{"id":"Q-LMqh38SK7R"},"source":["# Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dI2_MJk3SSou","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728669044507,"user_tz":-540,"elapsed":2807,"user":{"displayName":"colab plz","userId":"14508761458033416688"}},"outputId":"647e45f6-b495-4c73-d0ae-a72789aa496d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jg55_lrnSfF1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728669050111,"user_tz":-540,"elapsed":5606,"user":{"displayName":"colab plz","userId":"14508761458033416688"}},"outputId":"093b5329-84d7-41fd-b484-4debb52754c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip3 install torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grpLLPQfSK7T"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from tqdm import tqdm\n","import pandas as pd\n","from types import SimpleNamespace"]},{"cell_type":"markdown","metadata":{"id":"6Sm-nQFGSK7V"},"source":["# Hyperparameter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eX0iAE48SK7V"},"outputs":[],"source":["config = {\n","    \"learning_rate\": 2e-5,\n","    \"epoch\": 8,\n","    \"batch_size\": 32,\n","}\n","\n","CFG = SimpleNamespace(**config)"]},{"cell_type":"markdown","metadata":{"id":"sYLLtwYrSK7V"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBiQA9a6SK7W"},"outputs":[],"source":["RandomState=110\n","\n","train_df = pd.read_csv(\"/content/drive/MyDrive/gbt해커톤/data/train_df_1012_no_name_del.csv\")\n","test_df = pd.read_csv(\"/content/drive/MyDrive/gbt해커톤//data/test_df_1012_no_name_del.csv\")\n","sample_submission = pd.read_csv(\"/content/drive/MyDrive/gbt해커톤/data/sample_submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTDMHry2DSF8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728669061169,"user_tz":-540,"elapsed":3,"user":{"displayName":"colab plz","userId":"14508761458033416688"}},"outputId":"01217e65-d15c-414b-f2a2-1d86321275ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["23405\n","23405\n"]}],"source":["print(len(test_df))\n","print(len(sample_submission))"]},{"cell_type":"markdown","metadata":{"id":"Eu-_tWLYSK7W"},"source":["# Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEwl1aX8SK7W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728669064823,"user_tz":-540,"elapsed":3656,"user":{"displayName":"colab plz","userId":"14508761458033416688"}},"outputId":"29fbc758-e403-44b1-dfe9-f73b7de48f7d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n","The class this function is called from is 'ElectraTokenizer'.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import ElectraForSequenceClassification, ElectraTokenizer\n","import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = ElectraTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")\n","model = ElectraForSequenceClassification.from_pretrained(\"beomi/KcELECTRA-base-v2022\", num_labels=len(train_df['분류'].unique())).to(device)"]},{"cell_type":"markdown","metadata":{"id":"xApwJKBuSK7X"},"source":["# Custom Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iD-O8Y3BSK7X"},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=200):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        text = str(self.texts[item])\n","        label = self.labels[item] if self.labels is not None else -1\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","        return {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"os4FjjNBSK7Z"},"outputs":[],"source":["train_df.drop(columns=['제목'], inplace=True)\n","test_df.drop(columns=['제목'], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cW3w78cCSK7Z"},"outputs":[],"source":["# 레이블 인코딩\n","label_encoder = {label: i for i, label in enumerate(train_df['분류'].unique())}\n","train_df['label'] = train_df['분류'].map(label_encoder)\n","\n","# 데이터 분할 (train -> train + validation)\n","train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['분류'], random_state=RandomState)\n","\n","# 데이터셋 생성\n","train_dataset = TextDataset(train_df.키워드.tolist(), train_df.label.tolist(), tokenizer)\n","val_dataset = TextDataset(val_df.키워드.tolist(), val_df.label.tolist(), tokenizer)\n","test_dataset = TextDataset(test_df.키워드.tolist(), None, tokenizer)  # 라벨 없음\n","\n","# 데이터 로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Js0IS3lSK7Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728669065975,"user_tz":-540,"elapsed":806,"user":{"displayName":"colab plz","userId":"14508761458033416688"}},"outputId":"ace41849-f454-4e42-baa1-d2341f50d2f1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# 옵티마이저 및 학습 파라미터 설정\n","optimizer = AdamW(model.parameters(), lr=CFG.learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuLHal3uSK7Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab04c146-f8a9-4240-fe46-b70521994d85"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/8: 100%|██████████| 1358/1358 [25:47<00:00,  1.14s/it]\n","Validating: 100%|██████████| 340/340 [02:22<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation F1 Score: 0.30\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/8: 100%|██████████| 1358/1358 [25:12<00:00,  1.11s/it]\n","Validating: 100%|██████████| 340/340 [02:21<00:00,  2.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation F1 Score: 0.42\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/8:  40%|████      | 546/1358 [10:07<15:04,  1.11s/it]"]}],"source":["# 학습\n","model.train()\n","best_f1 = 0.0\n","patience = 2  # 성능 향상이 없을 때 기다리는 에포크 수\n","patience_counter = 0\n","\n","for epoch in range(CFG.epoch):\n","    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{CFG.epoch}'):\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Validation\n","    model.eval()\n","    val_predictions = []\n","    val_true_labels = []\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc='Validating'):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            _, preds = torch.max(outputs.logits, dim=1)\n","            val_predictions.extend(preds.cpu().tolist())\n","            val_true_labels.extend(labels.cpu().tolist())\n","\n","    # 검증 결과 출력\n","    val_f1 = f1_score(val_true_labels, val_predictions, average='macro')\n","    print(f\"Validation F1 Score: {val_f1:.2f}\")\n","\n","    # 조기 종료 체크\n","    if val_f1 > best_f1:\n","        best_f1 = val_f1\n","        patience_counter = 0  # 성능 향상이 있었으므로 카운터 초기화\n","        # 모델 저장 등 추가 작업을 여기서 수행할 수 있습니다.\n","    else:\n","        patience_counter += 1\n","\n","    # patience 초과 시 학습 종료\n","    if patience_counter >= patience:\n","        print(\"Early stopping triggered.\")\n","        break\n"]},{"cell_type":"markdown","metadata":{"id":"PJIHgIqlSK7Z"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bkefx19fSK7a"},"outputs":[],"source":["# 테스트 세트 추론\n","model.eval()\n","test_predictions = []\n","with torch.no_grad():\n","    for batch in tqdm(test_loader, desc='Testing'):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        _, preds = torch.max(outputs.logits, dim=1)\n","        test_predictions.extend(preds.cpu().tolist())\n","\n","# 라벨 디코딩\n","label_decoder = {i: label for label, i in label_encoder.items()}\n","decoded_predictions = [label_decoder[pred] for pred in test_predictions]"]},{"cell_type":"markdown","metadata":{"id":"gTbV9ZSESK7a"},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CKF_RxdjSK7a"},"outputs":[],"source":["sample_submission[\"분류\"] = decoded_predictions\n","\n","sample_submission.to_csv(\"/content/drive/MyDrive/gbt해커톤/submission/1012_no_submission.csv\", encoding='UTF-8-sig', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNuwpDLJEn8O"},"outputs":[],"source":["sample_submission['분류'].value_counts()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"nbformat":4,"nbformat_minor":0}