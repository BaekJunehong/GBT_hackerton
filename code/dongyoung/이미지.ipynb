{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# # 모델 로드\n",
    "# age_model = load_model(\"C:/Users/KimDongyoung/Desktop/이미지/age_model.keras\")\n",
    "# gender_model = load_model(\"C:/Users/KimDongyoung/Desktop/이미지/gender_model.keras\")\n",
    "\n",
    "# # Haar Cascade 얼굴 인식 모델 로드\n",
    "# face_cascade = cv2.CascadeClassifier(\"C:/Users/KimDongyoung/Desktop/이미지/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# # 웹캠 불러오기\n",
    "# camera = cv2.VideoCapture(0)\n",
    "\n",
    "# # 웹캠 해상도 설정\n",
    "# camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # 해상도를 1280x720으로 변경\n",
    "# camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# image_size = 64  # 모델에 맞는 이미지 크기\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = camera.read()\n",
    "#     if not ret:  # 웹캠에서 프레임을 읽지 못한 경우\n",
    "#         print(\"웹캠에서 프레임을 읽을 수 없습니다.\")\n",
    "#         break\n",
    "\n",
    "#     # 얼굴 탐지\n",
    "#     faces = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=8)\n",
    "\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         img = frame[y:y + h, x:x + w]\n",
    "#         img = cv2.resize(img, (image_size, image_size))\n",
    "\n",
    "#         # 예측 수행\n",
    "#         age_predict = age_model.predict(np.array(img).reshape(-1, image_size, image_size, 3))\n",
    "#         gender_predict = gender_model.predict(np.array(img).reshape(-1, image_size, image_size, 3))\n",
    "\n",
    "#         gend = np.round(gender_predict)\n",
    "#         col = (255, 255, 0) if gend == 0 else (203, 12, 255)\n",
    "#         gend_text = 'Man' if gend == 0 else 'Woman'\n",
    "\n",
    "#         # 결과 표시\n",
    "#         cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 225, 0), 1)\n",
    "#         cv2.putText(frame, f\"Age: {int(np.round(age_predict))} / {gend_text}\",\n",
    "#                     (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, w * 0.005, col, 1)\n",
    "\n",
    "#     cv2.imshow(\"camera\", frame)\n",
    "\n",
    "#     key = cv2.waitKey(1)  # 키 입력 대기\n",
    "#     if key == 27 or key == ord('q'):  # ESC 또는 'q' 키로 종료\n",
    "#         break\n",
    "\n",
    "# # 자원 해제\n",
    "# camera.release()          # 웹캠 자원 해제\n",
    "# cv2.destroyAllWindows()   # 모든 OpenCV 창 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimDongyoung\\AppData\\Local\\Temp\\ipykernel_19532\\621038514.py:57: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, \"Age:\" + str(int(np.round(age_predict))) + \" / \" + str(gend),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'destroyAllqWindows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# 자판의 ESC키가 27, ESC 입력시 비디오창 종료\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestroyAllqWindows\u001b[49m()\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# 자원 해제\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'destroyAllqWindows'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# Haarcascade 파일 경로 설정\n",
    "face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "\n",
    "# Haarcascade 파일 로드\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Haarcascade 파일을 로드할 수 없습니다.')\n",
    "\n",
    "# 웹캠 초기화\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# 이미지 크기 설정\n",
    "image_size = 224\n",
    "\n",
    "# 모델 로드\n",
    "age_model = load_model(\"C:/Users/KimDongyoung/Desktop/이미지/age_model.keras\")\n",
    "gender_model = load_model(\"C:/Users/KimDongyoung/Desktop/이미지/gender_model.keras\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:  # 웹캠에서 프레임을 읽지 못한 경우\n",
    "        print(\"웹캠에서 프레임을 읽을 수 없습니다.\")\n",
    "        break\n",
    "\n",
    "    # 얼굴 탐지\n",
    "    faces = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=8)\n",
    "\n",
    "    age_ = []\n",
    "    gender_ = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        img = frame[y:y + h, x:x + w]\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        img = np.array(img).reshape(-1, image_size, image_size, 3) / 255.0  # 입력 데이터 크기 조정 및 정규화\n",
    "        img = img.astype('float32')  # 데이터 타입을 float32로 변환\n",
    "\n",
    "        # 모델의 입력 크기 확인\n",
    "        model_input_shape = age_model.input_shape[1:]  # (224, 224, 3)과 같은 형태\n",
    "\n",
    "        # 입력 데이터 크기 조정\n",
    "        if img.shape[1:] != model_input_shape:\n",
    "            img = cv2.resize(img[0], (model_input_shape[0], model_input_shape[1]))  # img[0]을 사용하여 크기 조정\n",
    "            img = np.array(img).reshape(-1, model_input_shape[0], model_input_shape[1], model_input_shape[2]) / 255.0\n",
    "            img = img.astype('float32')\n",
    "\n",
    "        age_predict = age_model.predict(img)\n",
    "        gender_predict = gender_model.predict(img)\n",
    "        age_.append(age_predict)\n",
    "        gender_.append(np.round(gender_predict))\n",
    "        gend = np.round(gender_predict)\n",
    "        if gend == 0:\n",
    "            gend = 'Man'\n",
    "            col = (255, 255, 0)\n",
    "        else:\n",
    "            gend = 'Woman'\n",
    "            col = (203, 12, 255)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 225, 0), 1)\n",
    "        cv2.putText(frame, \"Age:\" + str(int(np.round(age_predict))) + \" / \" + str(gend),\n",
    "                    (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, w * 0.005, col, 1)\n",
    "    cv2.imshow(\"camera\", frame)\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "    # 자판의 ESC키가 27, ESC 입력시 비디오창 종료\n",
    "    if key == 27:\n",
    "        cv2.destroyAllqWindows()\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "camera.release()          # 웹캠 자원 해제\n",
    "cv2.destroyAllWindows()   # 모든 OpenCV 창 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    }
   ],
   "source": [
    "# Haarcascade 파일 경로 설정\n",
    "face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "\n",
    "# Haarcascade 파일 로드\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Haarcascade 파일을 로드할 수 없습니다.')\n",
    "\n",
    "# 웹캠 초기화\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# 이미지 크기 설정\n",
    "image_size = 224\n",
    "\n",
    "# 모델 로드\n",
    "age_model = load_model(\"C:/Users/KimDongyoung/Desktop/이미지/age_model.keras\")\n",
    "gender_model = load_model(\"C:/Users/KimDongyoung/Desktop/이미지/gender_model.keras\")\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "\n",
    "# 이미지 저장 \n",
    "# 폴더 생성\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:  # 웹캠에서 프레임을 읽지 못한 경우\n",
    "        print(\"웹캠에서 프레임을 읽을 수 없습니다.\")\n",
    "        break\n",
    "\n",
    "    # 얼굴 탐지\n",
    "    faces = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=8)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        img = frame[y:y + h, x:x + w]\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        img = np.array(img).reshape(-1, image_size, image_size, 3) / 255.0  # 입력 데이터 크기 조정 및 정규화\n",
    "        img = img.astype('float32')  # 데이터 타입을 float32로 변환\n",
    "\n",
    "        # 모델의 입력 크기 확인\n",
    "        model_input_shape = age_model.input_shape[1:]  # (224, 224, 3)과 같은 형태\n",
    "\n",
    "        # 입력 데이터 크기 조정\n",
    "        if img.shape[1:] != model_input_shape:\n",
    "            img = cv2.resize(img[0], (model_input_shape[0], model_input_shape[1]))  # img[0]을 사용하여 크기 조정\n",
    "            img = np.array(img).reshape(-1, model_input_shape[0], model_input_shape[1], model_input_shape[2]) / 255.0\n",
    "            img = img.astype('float32')\n",
    "\n",
    "        age_predict = age_model.predict(img)\n",
    "        gender_predict = gender_model.predict(img)\n",
    "        age_ = int(np.round(age_predict[0][0]))\n",
    "        gender_ = 'Man' if np.round(gender_predict[0][0]) == 0 else 'Woman'\n",
    "\n",
    "        # 결과를 리스트에 저장\n",
    "        results.append({\n",
    "            'image_name': f'image_{len(results) + 1}.jpg',\n",
    "            'age': age_,\n",
    "            'gender': gender_\n",
    "        })\n",
    "\n",
    "        # 얼굴 부분만 저장\n",
    "        face_img = frame[y:y + h, x:x + w]\n",
    "        cv2.imwrite(os.path.join('images', f'image_{len(results)}.jpg'), face_img)\n",
    "\n",
    "        # 결과 표시\n",
    "        col = (255, 255, 0) if gender_ == 'Man' else (203, 12, 255)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 225, 0), 1)\n",
    "        cv2.putText(frame, f\"Age: {age_} / {gender_}\",\n",
    "                    (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, w * 0.005, col, 1)\n",
    "\n",
    "    cv2.imshow(\"camera\", frame)\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "    # 자판의 ESC키가 27, ESC 입력시 비디오창 종료\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "camera.release()          # 웹캠 자원 해제\n",
    "cv2.destroyAllWindows()   # 모든 OpenCV 창 닫기\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: images\\image_10.jpg\n",
      "Deleted: images\\image_11.jpg\n",
      "Deleted: images\\image_12.jpg\n",
      "Deleted: images\\image_13.jpg\n",
      "Deleted: images\\image_14.jpg\n",
      "Deleted: images\\image_15.jpg\n",
      "Deleted: images\\image_16.jpg\n",
      "Deleted: images\\image_17.jpg\n",
      "Deleted: images\\image_18.jpg\n",
      "Deleted: images\\image_19.jpg\n",
      "Deleted: images\\image_2.jpg\n",
      "Deleted: images\\image_20.jpg\n",
      "Deleted: images\\image_21.jpg\n",
      "Deleted: images\\image_22.jpg\n",
      "Deleted: images\\image_23.jpg\n",
      "Deleted: images\\image_24.jpg\n",
      "Deleted: images\\image_25.jpg\n",
      "Deleted: images\\image_26.jpg\n",
      "Deleted: images\\image_27.jpg\n",
      "Deleted: images\\image_28.jpg\n",
      "Deleted: images\\image_29.jpg\n",
      "Deleted: images\\image_3.jpg\n",
      "Deleted: images\\image_30.jpg\n",
      "Deleted: images\\image_31.jpg\n",
      "Deleted: images\\image_32.jpg\n",
      "Deleted: images\\image_33.jpg\n",
      "Deleted: images\\image_34.jpg\n",
      "Deleted: images\\image_35.jpg\n",
      "Deleted: images\\image_36.jpg\n",
      "Deleted: images\\image_37.jpg\n",
      "Deleted: images\\image_4.jpg\n",
      "Deleted: images\\image_5.jpg\n",
      "Deleted: images\\image_6.jpg\n",
      "Deleted: images\\image_7.jpg\n",
      "Deleted: images\\image_8.jpg\n",
      "Deleted: images\\image_9.jpg\n"
     ]
    }
   ],
   "source": [
    "def delete_all_but_first_image(folder_path):\n",
    "    \"\"\"\n",
    "    'images' 폴더에 저장된 모든 파일 중 맨 처음에 찍힌 사진을 제외한 나머지 파일을 삭제합니다.\n",
    "    \"\"\"\n",
    "    # 폴더 내 모든 파일 목록을 가져옵니다.\n",
    "    files = sorted(os.listdir(folder_path))\n",
    "    \n",
    "    # 맨 처음에 찍힌 사진을 제외한 나머지 파일을 삭제합니다.\n",
    "    if len(files) > 1:\n",
    "        for file in files[1:]:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "    else:\n",
    "        print(\"폴더에 파일이 하나만 있거나 비어 있습니다.\")\n",
    "\n",
    "# 사용 예시\n",
    "delete_all_but_first_image('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: .\\1012_roberta_base(batch_64_max64)__.csv\n",
      "Deleted: .\\results.csv\n",
      "Deleted: .\\soft_voting_logNrf_DY.csv\n",
      "Deleted: .\\test_df_1007.csv\n",
      "Deleted: .\\test_df_1008.csv\n",
      "Deleted: .\\train_df_1007.csv\n",
      "Deleted: .\\train_df_1008.csv\n"
     ]
    }
   ],
   "source": [
    "def keep_first_csv_and_delete_others(csv_path):\n",
    "    \"\"\"\n",
    "    CSV 파일 중 맨 처음에 저장된 파일을 제외한 나머지 파일을 삭제합니다.\n",
    "    \"\"\"\n",
    "    # 폴더 내 모든 CSV 파일 목록을 가져옵니다.\n",
    "    files = sorted([f for f in os.listdir(csv_path) if f.endswith('.csv')])\n",
    "    \n",
    "    # 맨 처음에 저장된 CSV 파일을 제외한 나머지 파일을 삭제합니다.\n",
    "    if len(files) > 1:\n",
    "        for file in files[1:]:\n",
    "            file_path = os.path.join(csv_path, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "    else:\n",
    "        print(\"폴더에 CSV 파일이 하나만 있거나 비어 있습니다.\")\n",
    "\n",
    "keep_first_csv_and_delete_others('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
