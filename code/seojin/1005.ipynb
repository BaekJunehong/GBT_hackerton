{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. GBT_hackerton/translate_del_code.ipynb\n",
        "2. **숫자+영어, 영어+숫자, 숫자+영어+숫자, 영어+숫자+영어** 제거  \n",
        "  ['GS25', 'G90', '3D', 'RE100', 'XM3','GV70', 'GV80', 'KF94', 'QM6', 'EV6', 'HBM', 'IFRS17', 'COP26', 'COP27', 'COP28','B2B', 'H5N', 'B2C', 'P2P']  제외"
      ],
      "metadata": {
        "id": "LbztUJ-iG03e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdCZxkPEtZ7u",
        "outputId": "d9771258-45a5-4a35-c4a3-5b9b2901edb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e8564ca"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15f9a2fd"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/seojin/data/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/seojin/data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '키워드' 열에서 '기사'와 '구글' 두 단어를 모두 포함하는 행을 찾는 조건\n",
        "condition_train = train_df['키워드'].apply(lambda x: all(word in x for word in ['기사', '구글']))\n",
        "condition_test = test_df['키워드'].apply(lambda x: all(word in x for word in ['기사', '구글']))\n",
        "\n",
        "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
        "filtered_train_df = train_df[condition_train].copy()\n",
        "filtered_test_df = test_df[condition_test].copy()\n",
        "\n",
        "# '기사, 구글' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
        "def remove_keywords(text):\n",
        "    keywords = ['기사', '구글']\n",
        "    start_index = 0\n",
        "    for keyword in keywords:\n",
        "        start_index = text.find(keyword, start_index)\n",
        "        if start_index == -1:\n",
        "            return text\n",
        "        start_index += len(keyword)\n",
        "    return text[:text.find('기사')].strip()\n",
        "\n",
        "# 각 행의 '키워드' 값에서 '기사' 단어부터 마지막 단어까지 삭제\n",
        "filtered_train_df['키워드'] = filtered_train_df['키워드'].apply(remove_keywords)\n",
        "filtered_test_df['키워드'] = filtered_test_df['키워드'].apply(remove_keywords)\n",
        "\n",
        "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
        "train_df.loc[condition_train, '키워드'] = filtered_train_df['키워드']\n",
        "test_df.loc[condition_test, '키워드'] = filtered_test_df['키워드']"
      ],
      "metadata": {
        "id": "8H8JsUxO1mma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '키워드' 열에서 '영문', '번역', '오류', '전제' 네 단어를 모두 포함하는 행을 찾는 조건\n",
        "condition_train = train_df['키워드'].apply(lambda x: all(word in x for word in ['영문', '번역', '오류', '전제']))\n",
        "condition_test = test_df['키워드'].apply(lambda x: all(word in x for word in ['영문', '번역', '오류', '전제']))\n",
        "\n",
        "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
        "filtered_train_df = train_df[condition_train].copy()\n",
        "filtered_test_df = test_df[condition_test].copy()\n",
        "\n",
        "# '영문, 번역, 오류, 전제' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
        "def remove_keywords(text):\n",
        "    keywords = ['영문', '번역', '오류', '전제']\n",
        "    start_index = 0\n",
        "    for keyword in keywords:\n",
        "        start_index = text.find(keyword, start_index)\n",
        "        if start_index == -1:\n",
        "            return text\n",
        "        start_index += len(keyword)\n",
        "    return text[:text.find('영문')].strip()\n",
        "\n",
        "# 각 행의 '키워드' 값에서 '영문' 단어부터 마지막 단어까지 삭제\n",
        "filtered_train_df['키워드'] = filtered_train_df['키워드'].apply(remove_keywords)\n",
        "filtered_test_df['키워드'] = filtered_test_df['키워드'].apply(remove_keywords)\n",
        "\n",
        "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
        "train_df.loc[condition_train, '키워드'] = filtered_train_df['키워드']\n",
        "test_df.loc[condition_test, '키워드'] = filtered_test_df['키워드']"
      ],
      "metadata": {
        "id": "XGCNL-1A1mkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '키워드' 열에서 '구글', '번역기', '번역', '영문기사' 네 단어를 모두 포함하는 행을 찾는 조건\n",
        "condition_train = train_df['키워드'].apply(lambda x: all(word in x for word in ['구글', '번역기', '번역', '영문기사']))\n",
        "condition_test = test_df['키워드'].apply(lambda x: all(word in x for word in ['구글', '번역기', '번역', '영문기사']))\n",
        "\n",
        "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
        "filtered_train_df = train_df[condition_train].copy()\n",
        "filtered_test_df = test_df[condition_test].copy()\n",
        "\n",
        "# '구글, 번역기, 번역, 영문기사' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
        "def remove_keywords(text):\n",
        "    keywords = ['구글', '번역기', '번역', '영문기사']\n",
        "    start_index = 0\n",
        "    for keyword in keywords:\n",
        "        start_index = text.find(keyword, start_index)\n",
        "        if start_index == -1:\n",
        "            return text\n",
        "        start_index += len(keyword)\n",
        "    return text[:text.find('구글')].strip()\n",
        "\n",
        "# 각 행의 '키워드' 값에서 '구글' 단어부터 마지막 단어까지 삭제\n",
        "filtered_train_df['키워드'] = filtered_train_df['키워드'].apply(remove_keywords)\n",
        "filtered_test_df['키워드'] = filtered_test_df['키워드'].apply(remove_keywords)\n",
        "\n",
        "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
        "train_df.loc[condition_train, '키워드'] = filtered_train_df['키워드']\n",
        "test_df.loc[condition_test, '키워드'] = filtered_test_df['키워드']"
      ],
      "metadata": {
        "id": "CtPN9_Ep1mhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '키워드' 열에서 '구글번역', '번역' 두 단어를 모두 포함하는 행을 찾는 조건\n",
        "condition_train = train_df['키워드'].apply(lambda x: all(word in x for word in ['구글번역', '번역']))\n",
        "condition_test = test_df['키워드'].apply(lambda x: all(word in x for word in ['구글번역', '번역']))\n",
        "\n",
        "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
        "filtered_train_df = train_df[condition_train].copy()\n",
        "filtered_test_df = test_df[condition_test].copy()\n",
        "\n",
        "# '구글번역, 번역' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
        "def remove_keywords(text):\n",
        "    keywords = ['구글번역', '번역']\n",
        "    start_index = 0\n",
        "    for keyword in keywords:\n",
        "        start_index = text.find(keyword, start_index)\n",
        "        if start_index == -1:\n",
        "            return text\n",
        "        start_index += len(keyword)\n",
        "    return text[:text.find('구글번역')].strip()\n",
        "\n",
        "# 각 행의 '키워드' 값에서 '구글번역' 단어부터 마지막 단어까지 삭제\n",
        "filtered_train_df['키워드'] = filtered_train_df['키워드'].apply(remove_keywords)\n",
        "filtered_test_df['키워드'] = filtered_test_df['키워드'].apply(remove_keywords)\n",
        "\n",
        "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
        "train_df.loc[condition_train, '키워드'] = filtered_train_df['키워드']\n",
        "test_df.loc[condition_test, '키워드'] = filtered_test_df['키워드']"
      ],
      "metadata": {
        "id": "BQiwLmZB1qxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def remove_english_after_korean(text):\n",
        "    # 한글과 영어 단어를 구분하는 정규 표현식\n",
        "    korean_pattern = re.compile(r'[가-힣]+')\n",
        "    english_pattern = re.compile(r'[a-zA-Z]+')\n",
        "\n",
        "    korean_count = 0\n",
        "    english_count = 0\n",
        "    start_index = 0\n",
        "\n",
        "    words = text.split(',')\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if korean_pattern.search(word):\n",
        "            korean_count += 1\n",
        "        elif english_pattern.search(word):\n",
        "            english_count += 1\n",
        "            if english_count == 1:\n",
        "                start_index = i\n",
        "            if english_count >= 5:\n",
        "                return ','.join(words[:start_index])\n",
        "\n",
        "    return text\n",
        "\n",
        "# '키워드' 열에 함수 적용\n",
        "train_df['키워드'] = train_df['키워드'].apply(remove_english_after_korean)\n",
        "test_df['키워드'] = test_df['키워드'].apply(remove_english_after_korean)"
      ],
      "metadata": {
        "id": "avWJKKNV1qud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def remove_last_keywords(text):\n",
        "    keywords_to_remove = ['기사', 'Google', '번역', '번역']\n",
        "    words = text.strip(',').split(',')\n",
        "\n",
        "    # 마지막 4개의 단어가 keywords_to_remove와 일치하는지 확인\n",
        "    if words[-4:] == keywords_to_remove:\n",
        "        return ','.join(words[:-4]) + ',' if len(words[:-4]) > 0 else ''\n",
        "\n",
        "    return text\n",
        "\n",
        "# '키워드' 열에 함수 적용\n",
        "train_df['키워드'] = train_df['키워드'].apply(remove_last_keywords)\n",
        "test_df['키워드'] = test_df['키워드'].apply(remove_last_keywords)"
      ],
      "metadata": {
        "id": "-Z4QV5dN1qr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "숫자+영어  \n",
        "영어+숫자  \n",
        "숫자+영어+숫자  \n",
        "영어+숫자+영어  \n",
        "제거"
      ],
      "metadata": {
        "id": "H4MezPGk9kez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "patterns = {\n",
        "    '숫자+영어': r'\\b\\d+[a-zA-Z]+\\b',\n",
        "    '영어+숫자': r'\\b[a-zA-Z]+\\d+\\b',\n",
        "    '숫자+영어+숫자': r'\\b\\d+[a-zA-Z]+\\d+\\b',\n",
        "    '영어+숫자+영어': r'\\b[a-zA-Z]+\\d+[a-zA-Z]+\\b'\n",
        "}\n",
        "\n",
        "# 제외할 키워드 목록\n",
        "exclude_keywords = [\n",
        "    'GS25', 'G90', '3D', 'RE100', 'XM3',\n",
        "    'GV70', 'GV80', 'KF94', 'QM6', 'EV6',\n",
        "    'HBM', 'IFRS17', 'COP26', 'COP27', 'COP28',\n",
        "    'B2B', 'H5N', 'B2C', 'P2P'\n",
        "]\n",
        "\n",
        "# 키워드에서 패턴에 해당하는 단어를 삭제하는 함수\n",
        "def remove_pattern_keywords(df, patterns, exclude_keywords):\n",
        "    # 키워드 처리 함수\n",
        "    def process_keywords(keywords):\n",
        "        # 기존 키워드를 쉼표로 나누기\n",
        "        keyword_list = keywords.split(',')\n",
        "        # 새로운 키워드 리스트\n",
        "        new_keywords = []\n",
        "\n",
        "        for word in keyword_list:\n",
        "            # 패턴에 해당하면 삭제, 제외할 단어는 유지\n",
        "            should_keep = True\n",
        "            for label, pattern in patterns.items():\n",
        "                if re.search(pattern, word):\n",
        "                    if word not in exclude_keywords:\n",
        "                        should_keep = False\n",
        "                        break\n",
        "\n",
        "            # 새로운 키워드 리스트에 추가\n",
        "            if should_keep:\n",
        "                new_keywords.append(word)\n",
        "            else:\n",
        "                new_keywords.append('')  # 삭제된 경우 빈 문자열 추가\n",
        "\n",
        "        # 빈 문자열 제거 후 다시 쉼표로 합치기\n",
        "        return ','.join(filter(None, new_keywords))\n",
        "\n",
        "    # 키워드 처리\n",
        "    df['키워드'] = df['키워드'].apply(lambda x: process_keywords(x))\n",
        "    return df\n",
        "\n",
        "# train_df와 test_df에 대해 각각 처리\n",
        "train_df = remove_pattern_keywords(train_df, patterns, exclude_keywords)\n",
        "test_df = remove_pattern_keywords(test_df, patterns, exclude_keywords)"
      ],
      "metadata": {
        "id": "wzKMGtOrr1FU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}