{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 지정\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train_df_translate_del.csv\")\n",
    "test_df = pd.read_csv(\"./data/test_df_translate_del.csv\")  \n",
    "submission = pd.read_csv(\"./data/sample_submission.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23405\n",
      "23405\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df))\n",
    "print(len(submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame에서 NaN 값이 있는 행들:\n",
      "Empty DataFrame\n",
      "Columns: [ID, 분류, 제목, 키워드]\n",
      "Index: []\n",
      "\n",
      "Test DataFrame에서 NaN 값이 있는 행들:\n",
      "Empty DataFrame\n",
      "Columns: [ID, 제목, 키워드]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# NaN 값을 찾는 함수\n",
    "def find_nan_values(df, column_name):\n",
    "    nan_rows = df[df[column_name].isna()]\n",
    "    return nan_rows\n",
    "\n",
    "# train_df와 test_df에서 '키워드' 열의 NaN 값 찾기\n",
    "nan_train = find_nan_values(train_df, '키워드')\n",
    "nan_test = find_nan_values(test_df, '키워드')\n",
    "\n",
    "print(\"Train DataFrame에서 NaN 값이 있는 행들:\")\n",
    "print(nan_train)\n",
    "\n",
    "print(\"\\nTest DataFrame에서 NaN 값이 있는 행들:\")\n",
    "print(nan_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영어로만 구성된 단어에 대한 처리 (주소 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 제거할 단어 리스트\n",
    "remove_words = ['http', 'www.', '.kr', '.net', '.com']\n",
    "\n",
    "def remove_specific_words(text):\n",
    "    words = text.split(',')\n",
    "    filtered_words = [word for word in words if not any(remove_word in word for remove_word in remove_words)]\n",
    "    return ','.join(filtered_words)\n",
    "\n",
    "# '키워드' 열에 함수 적용\n",
    "train_df['키워드'] = train_df['키워드'].apply(remove_specific_words)\n",
    "test_df['키워드'] = test_df['키워드'].apply(remove_specific_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23405\n",
      "23405\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df))\n",
    "print(len(submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI       3608\n",
      "SK       3319\n",
      "GTX      2956\n",
      "LH       2919\n",
      "IC       1842\n",
      "SNS      1644\n",
      "CCTV     1532\n",
      "GH       1510\n",
      "KLPGA    1410\n",
      "TF       1386\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 영어로만 된 단어를 필터링하는 함수\n",
    "def is_english(word):\n",
    "    return bool(re.match('^[a-zA-Z]+$', word))\n",
    "\n",
    "# 영어로만 된 단어를 추출하는 함수\n",
    "def extract_english_keywords(keywords):\n",
    "    words = keywords.split(',')\n",
    "    english_words = [word for word in words if is_english(word)]\n",
    "    return english_words\n",
    "\n",
    "# 모든 영어 단어를 하나의 리스트로 모으기\n",
    "all_english_words = []\n",
    "train_df['키워드'].apply(lambda x: all_english_words.extend(extract_english_keywords(x)))\n",
    "\n",
    "# 리스트를 시리즈로 변환하여 value_counts 호출\n",
    "english_word_counts = pd.Series(all_english_words).value_counts()\n",
    "\n",
    "# 상위 10개의 결과 출력\n",
    "print(english_word_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pandas 출력 옵션 설정\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# english_word_counts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 종류 총 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5541"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "갯수가 2개이하인 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame 상위 10개의 결과:\n",
      "AI       3608\n",
      "SK       3319\n",
      "GTX      2956\n",
      "LH       2919\n",
      "IC       1842\n",
      "SNS      1644\n",
      "CCTV     1532\n",
      "GH       1510\n",
      "KLPGA    1410\n",
      "TF       1386\n",
      "dtype: int64\n",
      "\n",
      "Test DataFrame 상위 10개의 결과:\n",
      "AI       1575\n",
      "SK       1358\n",
      "GTX      1275\n",
      "LH       1255\n",
      "GH        836\n",
      "IC        776\n",
      "SNS       717\n",
      "TF        619\n",
      "ESG       613\n",
      "KLPGA     579\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 영어로만 된 단어를 필터링하는 함수\n",
    "def is_english(word):\n",
    "    return bool(re.match('^[a-zA-Z]+$', word))\n",
    "\n",
    "# 영어로만 된 단어를 추출하는 함수\n",
    "def extract_english_keywords(keywords):\n",
    "    words = keywords.split(',')\n",
    "    english_words = [word for word in words if is_english(word)]\n",
    "    return english_words\n",
    "\n",
    "# 모든 영어 단어를 하나의 리스트로 모으기\n",
    "train_english_words = []\n",
    "test_english_words = []\n",
    "\n",
    "train_df['키워드'].apply(lambda x: train_english_words.extend(extract_english_keywords(x)))\n",
    "test_df['키워드'].apply(lambda x: test_english_words.extend(extract_english_keywords(x)))\n",
    "\n",
    "# 리스트를 시리즈로 변환하여 value_counts 호출\n",
    "train_english_word_counts = pd.Series(train_english_words).value_counts()\n",
    "test_english_word_counts = pd.Series(test_english_words).value_counts()\n",
    "\n",
    "# 2개 이하로 등장하는 단어 제거\n",
    "train_words_to_remove = train_english_word_counts[train_english_word_counts <= 2].index.tolist()\n",
    "test_words_to_remove = test_english_word_counts[test_english_word_counts <= 2].index.tolist()\n",
    "\n",
    "# 원본 데이터에서 해당 단어들을 제거하는 함수\n",
    "def remove_infrequent_words(keywords, words_to_remove):\n",
    "    words = keywords.split(',')\n",
    "    filtered_words = [word for word in words if word not in words_to_remove]\n",
    "    return ','.join(filtered_words)\n",
    "\n",
    "# 원본 데이터에 반영\n",
    "train_df['키워드'] = train_df['키워드'].apply(lambda x: remove_infrequent_words(x, train_words_to_remove))\n",
    "test_df['키워드'] = test_df['키워드'].apply(lambda x: remove_infrequent_words(x, test_words_to_remove))\n",
    "\n",
    "# 상위 10개의 결과 출력\n",
    "filtered_train_english_word_counts = train_english_word_counts[train_english_word_counts > 2]\n",
    "filtered_test_english_word_counts = test_english_word_counts[test_english_word_counts > 2]\n",
    "\n",
    "print(\"Train DataFrame 상위 10개의 결과:\")\n",
    "print(filtered_train_english_word_counts.head(10))\n",
    "\n",
    "print(\"\\nTest DataFrame 상위 10개의 결과:\")\n",
    "print(filtered_test_english_word_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23405\n",
      "23405\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df))\n",
    "print(len(submission))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 갯수 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_english_word_counts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제거후 train 영어단어 종류 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_train_english_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제거후 test 영어단어 종류 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1452"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_test_english_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당단어 있는지 찾기용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 정확히 'City' 단어를 포함하고 있는 행 필터링 / City플랫폼 이런 단어는 찾지 않음\n",
    "# filtered_df = train_df[train_df['키워드'].str.contains(r'\\bCity\\b', na=False)]\n",
    "\n",
    "# # 결과 출력\n",
    "# len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'City' 단어를 포함하고 있는 행 필터링 / City플랫폼 이런 단어 포함 찾음\n",
    "# filtered_df = train_df[train_df['키워드'].str.contains(r'City', na=False)]\n",
    "\n",
    "# # 결과 출력\n",
    "# len(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
