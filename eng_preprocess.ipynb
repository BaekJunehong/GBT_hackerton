{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 지정\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train_df_translate_del.csv\")\n",
    "test_df = pd.read_csv(\"./data/test_df_translate_del.csv\")  \n",
    "submission = pd.read_csv(\"./data/sample_submission.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영어로만 구성된 단어에 대한 처리 (주소 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 제거할 단어 리스트\n",
    "remove_words = ['http', 'www.', '.kr', '.net', '.com']\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체\n",
    "train_df['키워드'] = train_df['키워드'].fillna('')\n",
    "test_df['키워드'] = test_df['키워드'].fillna('')\n",
    "\n",
    "# 필터링 조건 생성\n",
    "filter_condition_train = train_df['키워드'].apply(lambda x: not any(word in x for word in remove_words))\n",
    "filter_condition_test = test_df['키워드'].apply(lambda x: not any(word in x for word in remove_words))\n",
    "\n",
    "# 필터링된 데이터프레임 생성 및 원본 데이터프레임에 반영\n",
    "train_df = train_df[filter_condition_train]\n",
    "test_df = test_df[filter_condition_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK       1405\n",
      "SNS      1155\n",
      "LH       1015\n",
      "AI        910\n",
      "KLPGA     897\n",
      "GTX       746\n",
      "YTN       744\n",
      "TF        738\n",
      "NH        720\n",
      "CCTV      711\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 영어로만 된 단어를 필터링하는 함수\n",
    "def is_english(word):\n",
    "    return bool(re.match('^[a-zA-Z]+$', word))\n",
    "\n",
    "# 영어로만 된 단어를 추출하는 함수\n",
    "def extract_english_keywords(keywords):\n",
    "    words = keywords.split(',')\n",
    "    english_words = [word for word in words if is_english(word)]\n",
    "    return english_words\n",
    "\n",
    "# 모든 영어 단어를 하나의 리스트로 모으기\n",
    "all_english_words = []\n",
    "train_df['키워드'].apply(lambda x: all_english_words.extend(extract_english_keywords(x)))\n",
    "\n",
    "# 리스트를 시리즈로 변환하여 value_counts 호출\n",
    "english_word_counts = pd.Series(all_english_words).value_counts()\n",
    "\n",
    "# 상위 10개의 결과 출력\n",
    "print(english_word_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pandas 출력 옵션 설정\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# english_word_counts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 종류 총 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2207"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "갯수가 2개이하인 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame 상위 10개의 결과:\n",
      "SK       1405\n",
      "SNS      1155\n",
      "LH       1015\n",
      "AI        910\n",
      "KLPGA     897\n",
      "GTX       746\n",
      "YTN       744\n",
      "TF        738\n",
      "NH        720\n",
      "CCTV      711\n",
      "dtype: int64\n",
      "\n",
      "Test DataFrame 상위 10개의 결과:\n",
      "SK       588\n",
      "SNS      465\n",
      "LH       464\n",
      "AI       451\n",
      "KLPGA    361\n",
      "GTX      352\n",
      "TF       309\n",
      "YTN      298\n",
      "IC       297\n",
      "CCTV     280\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 영어로만 된 단어를 필터링하는 함수\n",
    "def is_english(word):\n",
    "    return bool(re.match('^[a-zA-Z]+$', word))\n",
    "\n",
    "# 영어로만 된 단어를 추출하는 함수\n",
    "def extract_english_keywords(keywords):\n",
    "    words = keywords.split(',')\n",
    "    english_words = [word for word in words if is_english(word)]\n",
    "    return english_words\n",
    "\n",
    "# 모든 영어 단어를 하나의 리스트로 모으기\n",
    "train_english_words = []\n",
    "test_english_words = []\n",
    "\n",
    "train_df['키워드'].apply(lambda x: train_english_words.extend(extract_english_keywords(x)))\n",
    "test_df['키워드'].apply(lambda x: test_english_words.extend(extract_english_keywords(x)))\n",
    "\n",
    "# 리스트를 시리즈로 변환하여 value_counts 호출\n",
    "train_english_word_counts = pd.Series(train_english_words).value_counts()\n",
    "test_english_word_counts = pd.Series(test_english_words).value_counts()\n",
    "\n",
    "# 2개 이하로 등장하는 단어 제거\n",
    "train_words_to_remove = train_english_word_counts[train_english_word_counts <= 2].index.tolist()\n",
    "test_words_to_remove = test_english_word_counts[test_english_word_counts <= 2].index.tolist()\n",
    "\n",
    "# 원본 데이터에서 해당 단어들을 제거하는 함수\n",
    "def remove_infrequent_words(keywords, words_to_remove):\n",
    "    words = keywords.split(',')\n",
    "    filtered_words = [word for word in words if word not in words_to_remove]\n",
    "    return ','.join(filtered_words)\n",
    "\n",
    "# 원본 데이터에 반영\n",
    "train_df['키워드'] = train_df['키워드'].apply(lambda x: remove_infrequent_words(x, train_words_to_remove))\n",
    "test_df['키워드'] = test_df['키워드'].apply(lambda x: remove_infrequent_words(x, test_words_to_remove))\n",
    "\n",
    "# 상위 10개의 결과 출력\n",
    "filtered_train_english_word_counts = train_english_word_counts[train_english_word_counts > 2]\n",
    "filtered_test_english_word_counts = test_english_word_counts[test_english_word_counts > 2]\n",
    "\n",
    "print(\"Train DataFrame 상위 10개의 결과:\")\n",
    "print(filtered_train_english_word_counts.head(10))\n",
    "\n",
    "print(\"\\nTest DataFrame 상위 10개의 결과:\")\n",
    "print(filtered_test_english_word_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 갯수 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_english_word_counts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제거후 train 영어단어 종류 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_train_english_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제거후 test 영어단어 종류 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_test_english_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당단어 있는지 찾기용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 정확히 'City' 단어를 포함하고 있는 행 필터링 / City플랫폼 이런 단어는 찾지 않음\n",
    "# filtered_df = train_df[train_df['키워드'].str.contains(r'\\bCity\\b', na=False)]\n",
    "\n",
    "# # 결과 출력\n",
    "# len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'City' 단어를 포함하고 있는 행 필터링 / City플랫폼 이런 단어 포함 찾음\n",
    "# filtered_df = train_df[train_df['키워드'].str.contains(r'City', na=False)]\n",
    "\n",
    "# # 결과 출력\n",
    "# len(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
