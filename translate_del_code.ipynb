{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 지정\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")  \n",
    "submission = pd.read_csv(\"./data/sample_submission.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영어 번역 내용 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# '키워드' 열에서 '영문', '번역', '오류', '전제' 네 단어를 모두 포함하는 행을 찾는 조건\n",
    "condition_train_1 = train_df['키워드'].apply(lambda x: all(word in x for word in ['영문', '번역', '오류', '전제']))\n",
    "condition_test_1 = test_df['키워드'].apply(lambda x: all(word in x for word in ['영문', '번역', '오류', '전제']))\n",
    "\n",
    "# '키워드' 열에서 '구글', '번역기', '번역', '영문기사' 네 단어를 모두 포함하는 행을 찾는 조건\n",
    "condition_train_2 = train_df['키워드'].apply(lambda x: all(word in x for word in ['구글', '번역기', '번역', '영문기사']))\n",
    "condition_test_2 = test_df['키워드'].apply(lambda x: all(word in x for word in ['구글', '번역기', '번역', '영문기사']))\n",
    "\n",
    "# '키워드' 열에서 '기사'와 '구글' 두 단어를 모두 포함하는 행을 찾는 조건\n",
    "condition_train_3 = train_df['키워드'].apply(lambda x: all(word in x for word in ['기사', '구글']))\n",
    "condition_test_3 = test_df['키워드'].apply(lambda x: all(word in x for word in ['기사', '구글']))\n",
    "\n",
    "# '키워드' 열에서 'Break' 단어를 포함하는 행을 찾는 조건\n",
    "condition_train_4 = train_df['키워드'].str.contains(r'\\bBreak\\b', na=False)\n",
    "condition_test_4 = test_df['키워드'].str.contains(r'\\bBreak\\b', na=False)\n",
    "\n",
    "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
    "filtered_train_df_1 = train_df[condition_train_1].copy()\n",
    "filtered_test_df_1 = test_df[condition_test_1].copy()\n",
    "filtered_train_df_2 = train_df[condition_train_2].copy()\n",
    "filtered_test_df_2 = test_df[condition_test_2].copy()\n",
    "filtered_train_df_3 = train_df[condition_train_3].copy()\n",
    "filtered_test_df_3 = test_df[condition_test_3].copy()\n",
    "filtered_train_df_4 = train_df[condition_train_4].copy()\n",
    "filtered_test_df_4 = test_df[condition_test_4].copy()\n",
    "\n",
    "# '영문, 번역, 오류, 전제' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
    "def remove_keywords_1(text):\n",
    "    keywords = ['영문', '번역', '오류', '전제']\n",
    "    start_index = 0\n",
    "    for keyword in keywords:\n",
    "        start_index = text.find(keyword, start_index)\n",
    "        if start_index == -1:\n",
    "            return text\n",
    "        start_index += len(keyword)\n",
    "    return text[:text.find('영문')].strip()\n",
    "\n",
    "# '구글, 번역기, 번역, 영문기사' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
    "def remove_keywords_2(text):\n",
    "    keywords = ['구글', '번역기', '번역', '영문기사']\n",
    "    start_index = 0\n",
    "    for keyword in keywords:\n",
    "        start_index = text.find(keyword, start_index)\n",
    "        if start_index == -1:\n",
    "            return text\n",
    "        start_index += len(keyword)\n",
    "    return text[:text.find('구글')].strip()\n",
    "\n",
    "# '기사, 구글' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
    "def remove_keywords_3(text):\n",
    "    keywords = ['기사', '구글']\n",
    "    start_index = 0\n",
    "    for keyword in keywords:\n",
    "        start_index = text.find(keyword, start_index)\n",
    "        if start_index == -1:\n",
    "            return text\n",
    "        start_index += len(keyword)\n",
    "    return text[:text.find('기사')].strip()\n",
    "\n",
    "# 한글 단어가 나오다가 영어 단어가 5번 이상 나오면 영어 단어가 나오기 시작한 단어부터 끝까지 삭제하는 함수 정의\n",
    "def remove_english_after_five(text):\n",
    "    # 영어 단어를 찾는 정규 표현식\n",
    "    english_words = re.findall(r'[a-zA-Z]+', text)\n",
    "    if len(english_words) >= 5:\n",
    "        # 5번째 영어 단어의 시작 위치 찾기\n",
    "        fifth_english_word = english_words[0]\n",
    "        start_index = text.find(fifth_english_word)\n",
    "        return text[:start_index].strip()\n",
    "    return text\n",
    "\n",
    "# 각 행의 '키워드' 값에서 해당 단어부터 마지막 단어까지 삭제\n",
    "filtered_train_df_1['키워드'] = filtered_train_df_1['키워드'].apply(remove_keywords_1)\n",
    "filtered_test_df_1['키워드'] = filtered_test_df_1['키워드'].apply(remove_keywords_1)\n",
    "filtered_train_df_2['키워드'] = filtered_train_df_2['키워드'].apply(remove_keywords_2)\n",
    "filtered_test_df_2['키워드'] = filtered_test_df_2['키워드'].apply(remove_keywords_2)\n",
    "filtered_train_df_3['키워드'] = filtered_train_df_3['키워드'].apply(remove_keywords_3)\n",
    "filtered_test_df_3['키워드'] = filtered_test_df_3['키워드'].apply(remove_keywords_3)\n",
    "filtered_train_df_4['키워드'] = filtered_train_df_4['키워드'].apply(remove_english_after_five)\n",
    "filtered_test_df_4['키워드'] = filtered_test_df_4['키워드'].apply(remove_english_after_five)\n",
    "\n",
    "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
    "train_df.loc[condition_train_1, '키워드'] = filtered_train_df_1['키워드']\n",
    "test_df.loc[condition_test_1, '키워드'] = filtered_test_df_1['키워드']\n",
    "train_df.loc[condition_train_2, '키워드'] = filtered_train_df_2['키워드']\n",
    "test_df.loc[condition_test_2, '키워드'] = filtered_test_df_2['키워드']\n",
    "train_df.loc[condition_train_3, '키워드'] = filtered_train_df_3['키워드']\n",
    "test_df.loc[condition_test_3, '키워드'] = filtered_test_df_3['키워드']\n",
    "train_df.loc[condition_train_4, '키워드'] = filtered_train_df_4['키워드']\n",
    "test_df.loc[condition_test_4, '키워드'] = filtered_test_df_4['키워드']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정된 데이터프레임을 CSV 파일로 저장\n",
    "train_df.to_csv('./data/train_df_translate_del.csv', index=False, encoding='utf-8-sig')\n",
    "test_df.to_csv('./data/test_df_translate_del.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
