{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 지정\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")  \n",
    "submission = pd.read_csv(\"./data/sample_submission.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영어 번역 내용 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기사, 구글 순서일때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '키워드' 열에서 '기사'와 '구글' 두 단어를 모두 포함하는 행을 찾는 조건\n",
    "condition_train = train_df['키워드'].apply(lambda x: all(word in x for word in ['기사', '구글']))\n",
    "condition_test = test_df['키워드'].apply(lambda x: all(word in x for word in ['기사', '구글']))\n",
    "\n",
    "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
    "filtered_train_df = train_df[condition_train].copy()\n",
    "filtered_test_df = test_df[condition_test].copy()\n",
    "\n",
    "# '기사, 구글' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
    "def remove_keywords(text):\n",
    "    keywords = ['기사', '구글']\n",
    "    start_index = 0\n",
    "    for keyword in keywords:\n",
    "        start_index = text.find(keyword, start_index)\n",
    "        if start_index == -1:\n",
    "            return text\n",
    "        start_index += len(keyword)\n",
    "    return text[:text.find('기사')].strip()\n",
    "\n",
    "# 각 행의 '키워드' 값에서 '기사' 단어부터 마지막 단어까지 삭제\n",
    "filtered_train_df['키워드'] = filtered_train_df['키워드'].apply(remove_keywords)\n",
    "filtered_test_df['키워드'] = filtered_test_df['키워드'].apply(remove_keywords)\n",
    "\n",
    "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
    "train_df.loc[condition_train, '키워드'] = filtered_train_df['키워드']\n",
    "test_df.loc[condition_test, '키워드'] = filtered_test_df['키워드']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영문, 번역, 오류, 전제 순서일때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '키워드' 열에서 '영문', '번역', '오류', '전제' 네 단어를 모두 포함하는 행을 찾는 조건\n",
    "condition_train = train_df['키워드'].apply(lambda x: all(word in x for word in ['영문', '번역', '오류', '전제']))\n",
    "condition_test = test_df['키워드'].apply(lambda x: all(word in x for word in ['영문', '번역', '오류', '전제']))\n",
    "\n",
    "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
    "filtered_train_df = train_df[condition_train].copy()\n",
    "filtered_test_df = test_df[condition_test].copy()\n",
    "\n",
    "# '영문, 번역, 오류, 전제' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
    "def remove_keywords(text):\n",
    "    keywords = ['영문', '번역', '오류', '전제']\n",
    "    start_index = 0\n",
    "    for keyword in keywords:\n",
    "        start_index = text.find(keyword, start_index)\n",
    "        if start_index == -1:\n",
    "            return text\n",
    "        start_index += len(keyword)\n",
    "    return text[:text.find('영문')].strip()\n",
    "\n",
    "# 각 행의 '키워드' 값에서 '영문' 단어부터 마지막 단어까지 삭제\n",
    "filtered_train_df['키워드'] = filtered_train_df['키워드'].apply(remove_keywords)\n",
    "filtered_test_df['키워드'] = filtered_test_df['키워드'].apply(remove_keywords)\n",
    "\n",
    "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
    "train_df.loc[condition_train, '키워드'] = filtered_train_df['키워드']\n",
    "test_df.loc[condition_test, '키워드'] = filtered_test_df['키워드']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구글, 번역기, 번역, 영문기사 순서일때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '키워드' 열에서 '구글', '번역기', '번역', '영문기사' 네 단어를 모두 포함하는 행을 찾는 조건\n",
    "condition_train = train_df['키워드'].apply(lambda x: all(word in x for word in ['구글', '번역기', '번역', '영문기사']))\n",
    "condition_test = test_df['키워드'].apply(lambda x: all(word in x for word in ['구글', '번역기', '번역', '영문기사']))\n",
    "\n",
    "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
    "filtered_train_df = train_df[condition_train].copy()\n",
    "filtered_test_df = test_df[condition_test].copy()\n",
    "\n",
    "# '구글, 번역기, 번역, 영문기사' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
    "def remove_keywords(text):\n",
    "    keywords = ['구글', '번역기', '번역', '영문기사']\n",
    "    start_index = 0\n",
    "    for keyword in keywords:\n",
    "        start_index = text.find(keyword, start_index)\n",
    "        if start_index == -1:\n",
    "            return text\n",
    "        start_index += len(keyword)\n",
    "    return text[:text.find('구글')].strip()\n",
    "\n",
    "# 각 행의 '키워드' 값에서 '구글' 단어부터 마지막 단어까지 삭제\n",
    "filtered_train_df['키워드'] = filtered_train_df['키워드'].apply(remove_keywords)\n",
    "filtered_test_df['키워드'] = filtered_test_df['키워드'].apply(remove_keywords)\n",
    "\n",
    "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
    "train_df.loc[condition_train, '키워드'] = filtered_train_df['키워드']\n",
    "test_df.loc[condition_test, '키워드'] = filtered_test_df['키워드']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구글번역, 번역 순서일때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '키워드' 열에서 '구글번역', '번역' 두 단어를 모두 포함하는 행을 찾는 조건\n",
    "condition_train = train_df['키워드'].apply(lambda x: all(word in x for word in ['구글번역', '번역']))\n",
    "condition_test = test_df['키워드'].apply(lambda x: all(word in x for word in ['구글번역', '번역']))\n",
    "\n",
    "# 조건을 만족하는 행들로 새로운 데이터프레임 생성\n",
    "filtered_train_df = train_df[condition_train].copy()\n",
    "filtered_test_df = test_df[condition_test].copy()\n",
    "\n",
    "# '구글번역, 번역' 순서로 단어가 나오는 부분을 찾아 삭제하는 함수 정의\n",
    "def remove_keywords(text):\n",
    "    keywords = ['구글번역', '번역']\n",
    "    start_index = 0\n",
    "    for keyword in keywords:\n",
    "        start_index = text.find(keyword, start_index)\n",
    "        if start_index == -1:\n",
    "            return text\n",
    "        start_index += len(keyword)\n",
    "    return text[:text.find('구글번역')].strip()\n",
    "\n",
    "# 각 행의 '키워드' 값에서 '구글번역' 단어부터 마지막 단어까지 삭제\n",
    "filtered_train_df['키워드'] = filtered_train_df['키워드'].apply(remove_keywords)\n",
    "filtered_test_df['키워드'] = filtered_test_df['키워드'].apply(remove_keywords)\n",
    "\n",
    "# 수정된 '키워드' 값을 원래 데이터프레임에 반영\n",
    "train_df.loc[condition_train, '키워드'] = filtered_train_df['키워드']\n",
    "test_df.loc[condition_test, '키워드'] = filtered_test_df['키워드']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기사,Google,번역,번역, 으로 남아있는 문장에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_last_keywords(text):\n",
    "    keywords_to_remove = ['기사', 'Google', '번역', '번역']\n",
    "    words = text.strip(',').split(',')\n",
    "    \n",
    "    # 마지막 4개의 단어가 keywords_to_remove와 일치하는지 확인\n",
    "    if words[-4:] == keywords_to_remove:\n",
    "        return ','.join(words[:-4]) + ',' if len(words[:-4]) > 0 else ''\n",
    "    \n",
    "    return text\n",
    "\n",
    "# '키워드' 열에 함수 적용\n",
    "train_df['키워드'] = train_df['키워드'].apply(remove_last_keywords)\n",
    "test_df['키워드'] = test_df['키워드'].apply(remove_last_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 -> 영어(7단어이상 이어질때) 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_english_after_korean(text):\n",
    "    # 한글과 영어 단어를 구분하는 정규 표현식\n",
    "    korean_pattern = re.compile(r'[가-힣]+')\n",
    "    english_pattern = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "    \n",
    "    english_count = 0\n",
    "    start_index = 0\n",
    "    \n",
    "    words = text.split(',')\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if english_pattern.search(word):\n",
    "            english_count += 1\n",
    "            if english_count == 1:\n",
    "                start_index = i\n",
    "            if english_count >= 7:\n",
    "                return ','.join(words[:start_index])\n",
    "        else:\n",
    "            english_count = 0  # 영어 단어가 연속되지 않으면 카운트 초기화\n",
    "    \n",
    "    return text\n",
    "\n",
    "def apply_function_if_last_word_is_english(df, column_name):\n",
    "    english_pattern = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "    \n",
    "    def conditionally_apply(text):\n",
    "        words = text.split(',')\n",
    "        if words and english_pattern.search(words[-1]):\n",
    "            return remove_english_after_korean(text)\n",
    "        return text\n",
    "    \n",
    "    df[column_name] = df[column_name].apply(conditionally_apply)\n",
    "\n",
    "# '키워드' 열에 함수 적용\n",
    "apply_function_if_last_word_is_english(train_df, '키워드')\n",
    "apply_function_if_last_word_is_english(test_df, '키워드')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "html문 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_specific_pattern(text):\n",
    "    # 시작과 끝 패턴 정의\n",
    "    start_pattern = r'monica-writing,entry-btn,root'\n",
    "    end_pattern = r'gc-guide,setting,hover,opacity,0\\.8'\n",
    "    \n",
    "    # 시작 패턴이 있는지 확인\n",
    "    if re.search(start_pattern, text):\n",
    "        # 끝 패턴이 있는지 확인하고, 있으면 그 부분까지 제거\n",
    "        if re.search(end_pattern, text):\n",
    "            # 시작 패턴부터 끝 패턴까지의 부분을 제거\n",
    "            text = re.sub(f'{start_pattern}.*?{end_pattern},', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def apply_pattern_removal(df):\n",
    "    # 정확히 일치하는 행 필터링\n",
    "    filtered_df = df[df['키워드'].str.contains(r'monica-writing', na=False)]\n",
    "    \n",
    "    # 필터링된 행에 대해 패턴 제거 함수 적용\n",
    "    df.loc[filtered_df.index, '키워드'] = filtered_df['키워드'].apply(remove_specific_pattern)\n",
    "\n",
    "# train_df와 test_df에 함수 적용\n",
    "apply_pattern_removal(train_df)\n",
    "apply_pattern_removal(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame에서 공백 값이 있는 행들:\n",
      "Empty DataFrame\n",
      "Columns: [ID, 분류, 제목, 키워드]\n",
      "Index: []\n",
      "\n",
      "Test DataFrame에서 공백 값이 있는 행들:\n",
      "Empty DataFrame\n",
      "Columns: [ID, 제목, 키워드]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 공백 값을 찾는 함수\n",
    "def find_blank_values(df, column_name):\n",
    "    blank_rows = df[df[column_name] == '']\n",
    "    return blank_rows\n",
    "\n",
    "# train_df와 test_df에서 '키워드' 열의 공백 값 찾기\n",
    "blank_train = find_blank_values(train_df, '키워드')\n",
    "blank_test = find_blank_values(test_df, '키워드')\n",
    "\n",
    "print(\"Train DataFrame에서 공백 값이 있는 행들:\")\n",
    "print(blank_train)\n",
    "\n",
    "print(\"\\nTest DataFrame에서 공백 값이 있는 행들:\")\n",
    "print(blank_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23405\n",
      "23405\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df))\n",
    "print(len(submission))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정된 데이터프레임을 CSV 파일로 저장\n",
    "train_df.to_csv('./data/train_df_translate_del.csv', index=False, encoding='utf-8-sig')\n",
    "test_df.to_csv('./data/test_df_translate_del.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
